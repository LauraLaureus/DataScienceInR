---
title: "ICD_ProyectoFinal"
author: "Laura del Pino Díaz"
date: "15/12/2016"
output: 
  pdf_document:
    toc: true
    toc_depth: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width=60)
knitr::opts_chunk$set(comment = "", warning = FALSE, message = FALSE, echo = TRUE, tidy = TRUE, size="small")

```
\newpage
#Introducción

En este proyecto vamos a realizar un análisis de dos bases de datos: la base de datos de la aprobación  de créditos en australia (australian credit approval) y el tiempo atmosférico de la ciudad de Izmir (wizmir).
 A partir de este análisis de los datos se realizará un estudios de modelos de clasificación con la base de datos de la aprobación de los créditos para determinar si se le pueden conceder o no el crédito. Mientras que con la base de datos del tiempo se elaaborarán distintos modelos de regresión con el objetivo de predecir la temperatura media.
 
#Las bases de datos

En este apartado estudiaremos las bases de datos _Australian Credit Approval(abreviado australian)_ para el problema de clasificación y _Weather of Izmir(abreviado wizmir)_ para el problema de regresión. 

##Australian (Australian Credit Approval)

La base de datos _australian credit approval_ tiene 15 atributos de los cuales actúan como predictores 14. 

Los atributos de esta base de datos en particular no tienen un nombre descriptivo que te permita conocer que es lo que representan los datos por razones de confidencialidad, tal y como se detalla en la página de [UCI](http://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29). Lo que si conocemos es el número de observaciones, 690, y los diferentes tipos de variables que componen la base de datos y el intervalo o valores que puede tomar cada variable y se enlistan a continuación. 

* A1 nominal  {0, 1}
* A2 real [16.0,8025.0]
* A3 real [0.0,26335.0]
* A4 nominal {1, 2, 3}
* A5 entero [1,14]
* A6 entero [1,9]
* A7 real [0.0,14415.0]
* A8 nominal {0, 1}
* A9 nominal {0, 1}
* A10 entero [0,67]
* A11 nominal {0, 1}
* A12 nominal {1, 2, 3}
* A13 entero [0,2000]
* A14 entero [1,100001]
* Class nominal {0,1}


  Dado la no descriptividad de los nombres no podemos realizar hipótesis previas sobre la base de datos. Por lo que procedemos a realizar un estudio de los principales estadísticos de cada variables. Este estudio lo haremos en dos partes: una parte dedicada a las variables numéricas y otra parte dedicada a las variables categóricas. 
  
```{r}
australian <- read.csv("./AustralianClassification/australian/australian.dat", comment.char = "@", header = FALSE)
names(australian) <- c("A1","A2","A3","A4","A5","A6","A7","A8","A9","A10","A11","A12","A13","A14","A15")

numerical_australian <- australian[,c(-1,-4,-8,-9,-11,-12,-15)]
categorical_australian <- australian[,c(1,4,8,9,11,12)]
output_australian <- australian[,15]
```

\newpage


###Estudio de las variables numéricas

Son varios los parámetros que que nos permiten conocer con más detalle la base de datos aunque no se tenga un nombre descriptivo para cada una de las variables, ejemplo de esto es el número de valores perdidos, la media,mediana, moda y cuartiles.
Así mismo se hace necesario comprobar algunas asumciones que hacen determinados algoritmos que emplearemos en este problema de clasificación, como son los test de normalidad del conjunto de datos (para el algoritmo LDA y QDA) y la igualdad de las varianzas (para el algoritmo LDA).

####Estudio del número de valores perdidos
En la página web de la base de datos de _Australian Credit Approval_ se indica que la base de datos tiene valores perdidos, en esta sección vamos a comprobar qué variables tienen esos valores perdidos. 

```{r}
numerical_australian_na <- apply(is.na(numerical_australian),2,sum)
numerical_australian_na
```

Puesto que en las variables numéricas no hay valores perdidos, podemos seguir el estudio con las variables en este estado sin necesidad de imputar valores. 

####Estadísticos principales

```{r}

numerical_stats <- summary(numerical_australian) 
numerical_std <- apply(numerical_australian,2,sd)
numerical_stats <- rbind(numerical_stats, numerical_std)
numerical_stats
```

 Como podemos ver las variables con mayor varianza son la variable A2,A3,A7 y A14 debido a que los rangos que puede tomar dicha variable son mayores. 
 
 Algunos algoritmos como LDA y QDA realizan suposiciones sobre las variables que reciben a la entrada. En el caso LDA supone que los conjuntos que discriminan tienen la misma varianza y son poblaciones normalmente distribuidas. 

####Test de normalidad

 Establezcamos como hipótesis nula que todas las variables numéricas pertenecen a una misma distribución. Para comprobarlo realizaremos el test no paramétrico de Kruskal Wallis.
```{r}
kruskal.test(numerical_australian)
```

 Puesto que el p-value es menor que 0.05 rechazamos la hipótesis de que todas las variables siguen la misma distribución. 
 Necesitamos encontrar aquellas variables que sí que sigan una distribución normal, para ello someteremos a todas al test de Shapiro-Wilk.
```{r}
numerical_australian_shapiro <- apply(numerical_australian,2,shapiro.test)
numerical_australian_shapiro
```

  Dado que todos los p-value de todas las variables es menor que 0.05 deducimos que ninguna de las varibales sigue una distribución normal por lo que no se espera que ni el algoritmo LDA ni el algoritmo QDA funcionen bien para la clasificación. 
\newpage
 A continuación se muestran los gráficos de barras de todas las variables numéricas:
  
```{r}
barplot(table(numerical_australian[,1]), main = "Frecuencia de los valores de A2",xlab = "Valor de A2", ylab = "Frecuencia")
barplot(table(numerical_australian[,2]), main = "Frecuencia de los valores de A3",xlab = "Valor de A3", ylab = "Frecuencia")
barplot(table(numerical_australian[,3]), main = "Frecuencia de los valores de A5",xlab = "Valor de A5", ylab = "Frecuencia")
barplot(table(numerical_australian[,4]), main = "Frecuencia de los valores de A6",xlab = "Valor de A6", ylab = "Frecuencia")
barplot(table(numerical_australian[,5]), main = "Frecuencia de los valores de A7",xlab = "Valor de A7", ylab = "Frecuencia")
barplot(table(numerical_australian[,6]), main = "Frecuencia de los valores de A10",xlab = "Valor de A10", ylab = "Frecuencia")
barplot(table(numerical_australian[,7]), main = "Frecuencia de los valores de A13",xlab = "Valor de A13", ylab = "Frecuencia")
barplot(table(numerical_australian[,8]), main = "Frecuencia de los valores de A14",xlab = "Valor de A14", ylab = "Frecuencia")
```
Como ya habíamos visto de forma numérica, por las gráficas no se puede decir que ninguna de las variables numéricas sea una distribución normal. 

\newpage
####Información gráfica

  Vamos a mostrar los valores que toman cada una de las variables y a compararlas entre ellas con un scartter plot.

```{r}
pairs(numerical_australian, main = "Comparación de las variables numéricas con la salida", pch = 16)
```

  Puesto que es una base de datos para clasificación con dos clases tiene sentido que en todas ellas aparezcan las dos columnas. Pero verlas así en pequeño no nos permite deducir si esa variable aporta mucho o poco a la salida, por lo que vamos a realizar unos plots para analizar mejor los datos. 

\newpage
```{r}
plot(australian[,2],australian[,15], main = "Comparación A2 con la salida", pch = 16,xlab = "Variable A2", ylab = "Variable 15")
plot(australian[,3],australian[,15], main = "Comparación A3 con la salida", pch = 16,xlab = "Variable A3",ylab = "Variable 15")
plot(australian[,5],australian[,15], main = "Comparación A5 con la salida", pch = 16,xlab = "Variable A5",ylab = "Variable 15")
plot(australian[,6],australian[,15], main = "Comparación A6 con la salida", pch = 16,xlab = "Variable A6",ylab = "Variable 15")
plot(australian[,7],australian[,15], main = "Comparación A7 con la salida", pch = 16,xlab = "Variable A7",ylab = "Variable 15")
plot(australian[,10],australian[,15], main = "Comparación A10 con la salida", pch = 16,xlab = "Variable A10",ylab = "Variable 15")
plot(australian[,13],australian[,15], main = "Comparación A13 con la salida", pch = 16,xlab = "Variable A13",ylab = "Variable 15")
plot(australian[,14],australian[,15], main = "Comparación A15 con la salida", pch = 16,xlab = "Variable A14",ylab = "Variable 15")
```

  No podemos decir que ninguna de las variables numéricas sea realmente discriminante para la salida. Sin embargo, no descartaría la variable 14 para que intervenga un modelo de clasificación, porque para valores altos solamente da salida positiva para la clase 1.

####Estudio de las correlaciones
  Volvermos a representar las variables ahora dejando la variable de salida fuera
```{r}
pairs(australian[,c(-1,-4,-8,-9,-11,-12,-15)], main = "Comparación de las variables numéricas entre ellas",col=ifelse(australian[,15]== 1,"red","blue"), pch = 16)
```

   Aparentemente no hay relación entre las variables, lo que parece curioso es que cualquiera de las variables que interacciona con la variable 6 forma una nube de puntos que recuerda a un histograma. 

   Vamos a comprobar de forma numérica que no existe esta correlación, para ello calcular la correlación entre todos los pares de variables
```{r}
  cor(numerical_australian,method = "pearson")
```
   Como ya pensábamos nos existe correlación significativa entre ningún par de variables, pero llama la atención la correlación del 0.4 entre la variable A5 y la variable A6.
\newpage


###Estudio de las variables categóricas. 

  Las variables catergóricas merecen un estudio propio puesto que estadísticos como la media o la desviación típica no tienen un valor interesante ya que no tiene sentido si tenemos las clases 1,2,3 y que la clase media sea 2,2. Por ello los estadísticos que vamos a usar en esta sección son los cuartiles y  el valor más frecuente o moda. 
  Pero antes que nada vamos a estudiar si el conjunto de los datos categóricos continen valores pedidos

####Estudio de los valores perdidos

```{r}
categorical_australian_na <- apply(is.na(cbind(categorical_australian,output_australian)),2,sum)
categorical_australian_na
```

  Las variables categóricas no tienen valores perdidos, dado que en la página web de esta base de datos en UCI indica que si que tiene valores perdido, asumimos que la copia de la base de datos, obtenida de Prado,  que tenemos se le han imputado los valores perdidos antes de proporcionárnosla a los alumnos.
  
####Estudio de los estadísticos principales
 
 Como mencionamos anteriormente los estadísticos que nos interesan en estas variables categóricas son: el mínimo, el máximo, los cuartiles y la moda. Por suerte para nosotros todos estos valores los podemos obtener con un solo comando excepto la moda que la obtendremos aparte. 
 
```{r}
categorical_stats <- summary(australian[,c(1,4,8,9,11,12)])
categorical_stats <- categorical_stats[-4,]
```

   Para obtener el valor más frecuente o moda del conjunto haremos uso de la siguiente función:
   
```{r}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```

  Realizando la moda sobre cada una de las variables categóricas tenemos:
```{r}
categorical_stats <- rbind(categorical_stats, apply(australian[,c(1,4,8,9,11,12)], 2,Mode))
categorical_stats
```


La información anterior nos ilustra como se distribuye cada una de las variables pero no como se relacionan con la salida, para ello dibujaremos gráficos en donde comparamos la frecuencia de cada valor con respecto al valor que toma la salida. 
  
```{r fig.align="center", fig.height=6}
hist(australian[which(australian[,15] == 0),1],col=rgb(1,0,0,1), main ="Frecuencia de la variable A1", ylab = "Frecuencia", xlab = "Categoría")
hist(australian[which(australian[,15] == 1),1], col=rgb(0,0,1,0.4),add = TRUE)
legend("topleft",legend = c("A1 cuando la salida es 0", "A1 cuando la salida es 1"),  text.width = 0.5, col = c("red","blue"), pch = 16)

hist(australian[which(australian[,15] == 1),4], col=rgb(1,0,0,1), main ="Frecuencia de la variable A4", ylab = "Frecuencia", xlab = "Categoría")
hist(australian[which(australian[,15] == 0),4], col=rgb(0,0,1,0.4), add = T)
legend("topright",legend = c("A4 cuando la salida es 0", "A4 cuando la salida es 1"),  text.width = 0.8, col = c("red","blue"), pch = 16) 
 


hist(australian[which(australian[,15] == 0),8], col=rgb(1,0,0,1),main ="Frecuencia de la variable A8", ylab = "Frecuencia", xlab = "Categoría", xlim = c(0,3))
hist(australian[which(australian[,15] == 1),8], col=rgb(0,0,1,0.4), add = T)
legend("topright",legend = c("A8 cuando la salida es 0", "A8 cuando la salida es 1"),  text.width =1.2, col = c("red","blue"), pch = 16)


hist(australian[which(australian[,15] == 0),9], col=rgb(1,0,0,1), main ="Frecuencia de la variable A9", ylab = "Frecuencia", xlab = "Categoría")
hist(australian[which(australian[,15] == 1),9], col=rgb(0,0,1,0.4), add = T)
legend("topright",legend = c("A9 cuando la salida es 0", "A9 cuando la salida es 1"),  text.width = 0.5, col = c("red","blue"), pch = 16)

hist(australian[which(australian[,15] == 0),11], col=rgb(1,0,0,1),main ="Frecuencia de la variable A11", ylab = "Frecuencia", xlab = "Categoría", xlim = c(0,3))
hist(australian[which(australian[,15] == 1),11], col=rgb(0,0,1,0.4), add = T)
legend("topright",legend = c("A11 cuando la salida es 0", "A11 cuando la salida es 1"),  text.width = 1.2, col = c("red","blue"), pch = 16, cex=.8)


 hist(australian[which(australian[,15] == 0),12], col=rgb(1,0,0,1),main ="Frecuencia de la variable A12", ylab = "Frecuencia", xlab = "Categoría")
hist(australian[which(australian[,15] == 1),12], col=rgb(0,0,1,0.4), add = T)
legend("topright",legend = c("A12 cuando la salida es 0", "A12 cuando la salida es 1"),  text.width = 0.8, col = c("red","blue"), pch = 16, cex = .8)

```

Viendo las gráficas anteriores, vemos que la gran mayoría de las variables no discriminan bien la salida, pero las variables A8 y A9 si que discriminan bien la mayoría de los casos. 

De este estudio solo podemos concluir que pueden actuar como buenos discriminantes las variables categóricas A8 y A9 así como la variable A14. A primera vista no esperaría buenos resultados de ningún modelo, excepto del KNN que al ajustarse mejor a los datos puede ser más flexible.

\newpage
##Wizmir (Weather of Izmir)

La base de datos de _Weather of Izmir_ contiene datos referentes a distintas variables relacionadas con el tiempo aatmosférico, a saber:

*  Temperatura máxima (Max_temperature) real[36.7,105.0]
*  Temperatura mínima (Min_temperature) real[15.8,78.6]
*  Rocío (Dewpoint) real[13.6,64.4]
*  Precipitación (Precipitation) real[0.0,7.6]
*  Presión a nivel del mar (Sea_level_pressure) real[29.26,30.48]
*  Presión normal (Standard_pressure) real[2.3,10.1]
*  Visibilidad (Visibility) real[0.92,29.1]
*  Velocidad del viento (Wind_speed) real[4.72,68.8]
*  Velocidad máxima del viento (Max_wind_speed) real[16.11,55.24]
*  Temperatura media (Mean_temperature) real[29.4,89.9]

El objetivo con esta base de datos es calcular la temperatura media a partir de las demás variables de datos. 

Al contrario que el conjunto de datos anterior, los nombre de las variables son descriptivos lo que nos permite formular hipótesis antes de visualizar los datos.

###Hipótesis previas

Las hipótesis previas nos permite son una primera aproximación del modelo de datos, nos permite crear los primeros modelos a partir de los cuales iterar para obtener un mejor resultado. 

1. La temperatura media es un modelo lineal en el que intervienen la temperatura mínima y la temperatura máxima. Posiblemente 0.5xtemperatura mínima + 0.5xtemperatura máxima,por la propia definición de media. 
2. Por la ley física que relaciona la temperatura y la presión, a mayor presión mayor temperatura. No se espera que esta ley se cumpla por completo ya que está estipulada para gases de volumen constante, por esto tanto la presión como la presión a nivel del mar tienen que ver en cierta medida con la temperatura. 
3. La velocidad del viento y la velocidad máxima del mismo, no intervienen o lo hacen en una medida despreciable, puesto que son factores que intervienen más en la sensación térmica que en la propia temperatura. 
4. El rocío y las precipitaciones, tienen que ver más como consecuencia de la temperatura que como factor generador de la temperatura, no se descarta su intervención pero se espera que sea mínima. 
5. Sobre la visibilidad, no sabemos que comportamiento tendrá puesto que en ocasiones hay poca visibilidad a causa de  bancos de niebla que se generan por las altas temperaturas, pero en ciertas zonas del planeta puede ser por polvo en suspensión traido por el viento, que genera que haya mayor temperatuda, por ello como actuará esta variable en el modelo es todo un misterio.

Ahora con estas hipótesis previas, procedemos a estudiar las variables, que en este caso son solo numéricas, con respecto de la salida. 

###Variables numéricas.

En primer lugar vamos a cargar el dataset.

```{r}
wizmir <- read.csv("./WizmirRegression/wizmir/wizmir.dat", header = FALSE, comment.char = "@")
names(wizmir) <- c("Max_temperature","Min_temperature","Dewpoint","Precipitation","Sea_level_pressure","Standar _pressure","Visibility","Wind_speed","Wind_max_speed","Mean_temperature")
```
Tras ello vamos a obtener el número de valores perdidos que tenemos en el conjunto de datos.

####Estudio de los valores perdidos

```{r}
wizmir_na <- apply(is.na(wizmir),2,sum)
wizmir_na
```
Esta base de datos no tiene valores perdidos, lo que nos facilita el trabajo.

####Test de normalidad

 En este caso, el problema no es un problema de clasificación por lo que los algoritmos no hacen suposiciones de los datos de entrada como el caso anterior que necesitaba que los datos estuvieran normalmente distribuidos, por ello no vamos a realizar un estudio de la normalidad de los datos. 

####Estudio de los principales estadísticos

 La obtención de los principales valores estadísticos la obtenemos, como hemos visto en los casos anteriores, mediante la función summary. 

```{r}
summary(wizmir)
```

Exceptuando las variables de precipitación (Precipitation) y la presión normal (Standar_pressure) podemos decir que todas las variables se mueven en el mismo rango de 20-100 aproximadamente por lo que si se generase un modelo que no tuviese dichas variables podríamos evitar el paso intermedio de normalizar las variables para igualar el rango. 

Nos queda por conocer la desviación estándar de los datos:
```{r}
wizmir_std <- apply(wizmir[,],2,sd)
wizmir_std
```

Viendo las desviaciones típicas de la temperatura mínima y máxima tener un valor tan cercano al de la temperatura media, que es el valor que tenemos que obtener, hace pensar que podrían compartir distribución. 

\newpage
Si representamos el valor de todas las variables con respecto de la salida obtenemos los siguientes gráficos

```{r fig.align="center"}
plot(wizmir, main =  "Relación de las variables entre ellas", pch = 16)
```

Primero, nos vamos a concentrar en la última fila de la ilustración anterior, en ella están reflejadas todas las variables como variable de "entrada" o variable independiente y la variable de salida como variable independiente. En esta fila podemos ver que las variables de temperatura máxima y mínima tienen una relación lineal con la temperatura media, como era de esperar por la hipótesis 1, pero además esta tendencia lineal también la tiene la variable de rocío que puede ser debido a que el rocío es dependiente de la temperatura mínima,como se ve en la relación entre estas dos variables (y en la relación de la variable rocío con la temperatura máxima también) pero es un detalle a tener en cuenta a la hora de elaborar un modelo. 

Otras variables que podrían intervenir en el modelo de una forma, no tan claramente lineal o incluso de orden superior, son la presión a nivel del mar y la velocidad máxima del viento, puesto que dentro de la nube de puntos se puede dibujar una recta decreciente e incluso una curva.

El resto de variables la nube de puntos tiene tal dispersión que podrían no intervenir porque no se ve una función definida que encaje con los datos. 

####Estudio de correlación
Una forma de comprobar que la variable _Dewpoint_ o punto de rocío está relacionada con la temperatura mínima y/o máxima está en la tabla de correlaciones:

```{r}
cor(wizmir[,-10], method = "pearson")
```

Las correlaciones que podemos ver del cuadrante anterior son:
* La temperatura mínima y máxima están correlacionadas entre ellas.
* El punto de rocío está relacionado tanto con las temperaturas máxima y mínima y en menor medida, y de forma inversa, con la presión a nivel del mar.
* Tanto la temperatura máxima como mínima están relacionadas de forma inversa con la presión atmosférica a nivel del mar. 
* La visibilidad y la presión estándar tienen una ligera correlación.
* La visibilidad y la velocidad del viento están fuertemente correlacionadas. 


Como conclusión de estos datos diría que el mejor modelo para predecir la temperatura media es un modelo de regresión lineal donde intervengan las variables de temperatura máxima y mínima y habría que estudiar si añadir las variables de rocío y presión a nivel del mar supone alguna mejora. 

\newpage
#Regresión
  
  La regresión es el proceso estadístico por el que se estiman la relación entre una o varias variables independientes o predictoras y la variable dependiente, dado un conjunto de datos de entrada. El objetivo de la regresión es obtener un modelo que permita predecir o estimar el valor que tendrá un nuevo dato a su salida, siendo este dato distinto de todos los anteriores que se usaron para crear el modelo.
  Existen varios algoritmos para realizar regresión, pero en este trabajo solamente utilizaremos la regresión lineal simple, la regresión lineal múltiple y el algoritmo de los k- vecinos más cercanos. 
  
##Problema
  Utilizaremos regresión para predecir la temperatura media de la ciudad de Izmir que hemos estudiado anteriormente. 
   
##Regresores elegidos
   En el apartado de análisis de datos anterior pudimos ver que los mejores regresores para este problema son las variables:
   
* Temperatura máxima
* Temperatura mínima

  Pero vamos a realizar una prueba de regresión lineal simple con cinco regresores así que añadiremos a la lista:
  
* Punto de rocío
* Presión a nivel del mar
* Visibilidad

##Modelo de regresión simple

Con el modelo de regresión simple comprobamos que los datos se pueden explicar de la forma de una línea recta usando solamente una variable de predicción. La bondad de este modelo se pude medir por dos coeficientes: R^2 y el RMSE. El primer parámetro nos lo realizar la operación _summary_ sobre el modelo obtenido, pero el RMSE es preferible calcularlo a mano por ello definimos la siguiente función _rmse_.

```{r}
rmse <- function (original,algorithm_output){
  sqrt(sum((original-algorithm_output)^2)/length(algorithm_output))
}
```

Los modelos los crearemos haciendo uso de todos los datos del conjunto de datos

```{r}
lmModel_maxTemp = lm(wizmir$Mean_temperature ~ wizmir$Max_temperature)
lmModel_minTemp = lm(wizmir$Mean_temperature ~ wizmir$Min_temperature)
lmModel_dewPoint = lm(wizmir$Mean_temperature ~ wizmir$Dewpoint)
lmModel_seaPressure = lm(wizmir$Mean_temperature ~ wizmir$Sea_level_pressure)
lmModel_visibility = lm(wizmir$Mean_temperature ~ wizmir$Visibility)
```

Ahora obtendremos los dos parámetros de comparación:
```{r}
summary_maxTemp = summary(lmModel_maxTemp)
rSquared_maxTemp = summary_maxTemp$r.squared
adjusted_r_maxTemp = summary_maxTemp$adj.r.squared
rmse_maxTemp = rmse(wizmir$Mean_temperature,lmModel_maxTemp$fitted.values)

summary_minTemp = summary(lmModel_minTemp)
rSquared_minTemp = summary_minTemp$r.squared
adjusted_r_minTemp = summary_minTemp$adj.r.squared
rmse_minTemp = rmse(wizmir$Mean_temperature,lmModel_minTemp$fitted.values)

summary_dewPoint = summary(lmModel_dewPoint)
rSquared_dewPoint = summary_dewPoint$r.squared
adjusted_r_dewPoint = summary_dewPoint$adj.r.squared
rmse_dewPoint = rmse(wizmir$Mean_temperature,lmModel_dewPoint$fitted.values)

summary_seaPress = summary(lmModel_seaPressure)
rSquared_seaPress = summary_seaPress$r.squared
adjusted_r_seaPress = summary_seaPress$adj.r.squared
rmse_seaPress = rmse(wizmir$Mean_temperature,lmModel_seaPressure$fitted.values)

summary_visibility = summary(lmModel_visibility)
rSquared_visibility = summary_visibility$r.squared
adjusted_r_visibility = summary_visibility$adj.r.squared
rmse_visibility = rmse(wizmir$Mean_temperature,lmModel_visibility$fitted.values)

rSquared = c(rSquared_maxTemp,rSquared_minTemp,rSquared_dewPoint,rSquared_seaPress,rSquared_visibility)
adjRSquared = c(adjusted_r_maxTemp,adjusted_r_minTemp,adjusted_r_dewPoint,adjusted_r_seaPress,adjusted_r_visibility)
rmse_lm_results = c(rmse_maxTemp,rmse_minTemp,rmse_dewPoint,rmse_seaPress,rmse_visibility)

linealSimpleModels_comparisonDataFrame = data.frame(rSquared,adjRSquared,rmse_lm_results)
row.names(linealSimpleModels_comparisonDataFrame) <- c("MaxTemp", "MinTemp","DewPoint","SeaPressure","Visibility")
linealSimpleModels_comparisonDataFrame
```

De esta tabla si miramos la columna de la R^2 ( _rSquared_ ) podemos ver que la temperatura máxima es el mejor regresor del conjunto puesto con un modelo lineal simple explica el 95% de los casos, seguido de cerca por la temperatura mínima que explica el 91% de los casos. El resto de regresores no son tan buenos. 

La columna de la R^2 ajustada en este caso no tiene mucho sentido, puesto que es el parámetro de la R^2 ajustada al número de variables del modelo que en este caso es 1, pero se calcula para después poder comparar con el modelo de regresión múltiple. 

El RMSE crece a medida que el modelo es peor en la prediccion de la salida, siendo de prácticamente 3 para el caso de la temperatura máxima y de prácticamente 14 para el caso de la visibilidad que solamente explica el 5% de los casos. 

###Modelo de regresión lineal múltiple 

En la regresión lineal múltiple, se emplea un modelo matemático en el que intervienen varias variables a la vez, creando un hiperplano. 

En esta sección crearemos modelos de regresión lineal múltiple con la esperanza de mejorar el modelo lineal simple anterior. 

El primero que desarrollaremos intervienen únicamente las variables temperatura máxima y temperatura mínima, tal y como se propuso en la sección de hipótesis previas.

```{r}
lmmModel_maxMinTemp = lm(wizmir$Mean_temperature ~ wizmir$Max_temperature+wizmir$Min_temperature)
rmse_lmm_maxMin = rmse(wizmir$Mean_temperature, lmmModel_maxMinTemp$fitted.values)
summary_lmm_maxMin = summary(lmmModel_maxMinTemp)
c(summary_lmm_maxMin$r.squared,summary_lmm_maxMin$adj.r.squared,rmse_lmm_maxMin)
summary_lmm_maxMin

comparisonDF = rbind(linealSimpleModels_comparisonDataFrame, c(summary_lmm_maxMin$r.squared,summary_lmm_maxMin$adj.r.squared,rmse_lmm_maxMin))

```

Viendo los valores de R^2 y R^2 ajustado de 0.99 así como la reducción a menos de la mitad del RMSE, creo que será muy díficil encontrar un modelo capaz de mejorar este. Aún así, siguiendo el enunciado de la actividad elaboramos un modelo de regresión lineal múltiple en donde intervienen de forma conjunta los regresores de los modelos de regresión lineal. 

```{r}
lmmModel_simpleSubSet = lm(wizmir$Mean_temperature ~ wizmir$Max_temperature+wizmir$Min_temperature+wizmir$Dewpoint+wizmir$Sea_level_pressure+wizmir$Visibility)
summary_lmm_simpleSubset = summary(lmmModel_simpleSubSet)
rmse_lmm_simpleSubset = rmse(wizmir$Mean_temperature, lmmModel_simpleSubSet$fitted.values)
comparisonDF = rbind(comparisonDF, c(summary_lmm_simpleSubset$r.squared,summary_lmm_simpleSubset$adj.r.squared,rmse_lmm_simpleSubset))
```

La introducción de las tres variables del punto de rocío, la presión al nivel del mar y la visibilidad solamente mejora el modelo en una décima del parámetro de R^2 ajustado, por lo que ante la decisión de elegir este modelo u el otro preferiría el anterior por simplicidad.

####Modelos de regresión lineal múltiple con interacciones.
Ante los resultados del análisis de correlación tenemos que la temperatura mínima y máxima están muy correladas, por lo que vamos a crear un modelo de regresión lineal múltiple con una iteración entre ellas. 

```{r}
lmmInnt = lm(wizmir$Mean_temperature ~ wizmir$Max_temperature*wizmir$Min_temperature)
summary_lmm_Innt = summary(lmmInnt)
rmse_lmm_Innt = rmse(wizmir$Mean_temperature, lmmInnt$fitted.values)
comparisonDF = rbind(comparisonDF, c(summary_lmm_Innt$r.squared,summary_lmm_Innt$adj.r.squared,rmse_lmm_Innt))
summary_lmm_Innt
```

Si observamos la tabla de las variables que intervienen en el modelo, podemos ver como la interacción entre las dos variables de temperatura no es significativo. 
Además que los coeficientes de las dos temperaturas se acercan a la estimación de la hipótesis previa de que cada una de ellas intervienen en un 50%, cada una por la definición de media. 

El siguiente modelo se tiene en cuenta que las variables de temperatura están correladas con el punto de rocío. 
```{r}
lmmInnt2 = lm(wizmir$Mean_temperature ~ wizmir$Max_temperature*wizmir$Min_temperature*wizmir$Dewpoint)
summary_lmm_Innt2 = summary(lmmInnt2)
rmse_lmm_Innt2 = rmse(wizmir$Mean_temperature, lmmInnt2$fitted.values)
comparisonDF = rbind(comparisonDF, c(summary_lmm_Innt2$r.squared,summary_lmm_Innt2$adj.r.squared,rmse_lmm_Innt2))
summary_lmm_Innt2
```
Como se muestra en el resumen, la variable de punto de rocío, no es significante en el modelo al igual que su interacción con la variable punto de rocío. Por su lado, la interacción entre las tres variables es menos significante que el resto de variables. 

Viendo estos modelos con interacción, la afirmación anterior de que será difícil encontrar un modelo que mejore el modelo lineal múltiple en el que intervienen las dos temperaturas. 

####Modelos no lineales. 

Si rescatamos las representaciones de la temepratura media con respecto al punto de rocío y a la presión a nivel del mar podemos dudar de que el modelo que sigue es un modelo lineal o un modelo de orden dos. Por ello vamos a probar modelos en los que se le añaden estas dos variables al modelo lineal múltiple de las dos variables de temperatura. 

```{r}
lmmNL = lm(wizmir$Mean_temperature ~ wizmir$Max_temperature+wizmir$Min_temperature+poly(wizmir$Dewpoint,2))
summary_lmm_NL = summary(lmmNL)
rmse_lmm_NL = rmse(wizmir$Mean_temperature, lmmNL$fitted.values)
comparisonDF = rbind(comparisonDF, c(summary_lmm_NL$r.squared,summary_lmm_NL$adj.r.squared,rmse_lmm_NL))
summary_lmm_NL
```
Este modelo no supone ninguna diferencia con respecto a la modelo lineal múltiple con las dos temperaturas sin el punto de rocío. 

```{r}
lmmNL2 = lm(wizmir$Mean_temperature ~ wizmir$Max_temperature+wizmir$Min_temperature+poly(wizmir$Sea_level_pressure,2))
summary_lmm_NL2 = summary(lmmNL2)
rmse_lmm_NL2 = rmse(wizmir$Mean_temperature, lmmNL2$fitted.values)
comparisonDF = rbind(comparisonDF, c(summary_lmm_NL2$r.squared,summary_lmm_NL2$adj.r.squared,rmse_lmm_NL2))
summary_lmm_NL2
```
En este modelo todas las variables son significantes pero no supone ningún tipo de mejoría relevante si miramos el parámetro de la R^2 ajustada con respecto a los modelos anteriores. 

```{r}
row.names(comparisonDF) <-  c("MaxTemp", "MinTemp","DewPoint","SeaPressure","Visibility","ML_MinMax","ML_Subset","Innt_MinXMax", "Innt_XDewPoint","NL_DewPoint","NL_SeaPress")
comparisonDF
```

Como se puede comprobar de la tabla anterior, el modelo lineal de la temperatura máxima es lo suficientemente bueno por si solo aunque tiene un 5% de fallo que corrige casi por completo al añadir al modelo la temperatura mínima. Siendo este modelo el más simple que representa el 99% de los casos. 

###Modelo Knn con Cross-validation de 5-particiones
Otra técnica para elaborar un modelo de regresión es el modelo de los K vecinos más cercanos( _K nearest neighbours_ o _knn_), en esta técnica se utiliza la información de los k vecinos más cercanos para dar la salida a los datos de entrada. Este modelo tiende a ajustarse a los datos cuanto mayor sea el valor de k.

Vamos a combinar esta técnica con la validación cruzada. Esta técnica consiste en dividir los datos de entrada en n particiones, en este caso serán 5, aplicar el algoritmo seleccionando una de las particiones como test y el resto como entrenamiento para la elaboración del modelo. Una vez tenga el modelo obtendrá la bondad con la partición de test y guardará esta bondad para volver a crear el modelo a partir de una nueva selección de particiones y una nueva partición de test, y así hasta que todas las particiones hayan sido la partición de test. Entonces se hará una media de todas las bondades calculadas y se hará la media. 

Para la creación de un modelo del tipo Knn necesitamos de las librerías MASS y kknn de R por lo que las cargamos ahora con los comando require
```{r}
require("MASS")
require("kknn")
```

Cargamos con el siguiente comando las particiones:
```{r}
nombre <- "./WizmirRegression/wizmir/wizmir"
run_knn_fold <- function(i, x, tt = "test") {
  file <- paste(x, "-5-", i, "tra.dat", sep="")
  x_tra <- read.csv(file, comment.char="@")
  file <- paste(x, "-5-", i, "tst.dat", sep="")
  x_tst <- read.csv(file, comment.char="@")
  In <- length(names(x_tra)) - 1
  names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
  names(x_tra)[In+1] <- "Y"
  names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
  names(x_tst)[In+1] <- "Y"
  if (tt == "train") {
    test <- x_tra
  }
  else {
    test <- x_tst
  }
  fitMulti<- kknn(Y~.,x_tra,test)
  yprime=fitMulti$fitted.values
  sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}
```

Con los datos cargados obtenemos el error cuadrático de los modelos de kknn para la fase de entrenamiento y de testeo. 
```{r}
knnMSEtrain<-mean(sapply(1:5,run_knn_fold,nombre,"train"))
knnMSEtest<-mean(sapply(1:5,run_knn_fold,nombre,"test"))
knnMSEtrain
knnMSEtest
```
La diferencia es de 4, por lo que se deduce que el modelo knn se ajusta demasiado a los datos en la fase de entrenamiento. 

Si miramos estos errores con los obtenidos por los distintos modelos lineales anteriormente obtenidos 

```{r}
comparisonDF$rmse_lm_results
```


Vemos que el error de 2.53 podría aproximarse con el modelo de regresión lineal simple obtenido solamente con la variable temperatura máxima que tiene un 0.95 de valor en R^2, mientras que el error de 6.06 cae entre el error del modelo lineal simple de la temperatura mínima que tiene un valor de 0.91 de R^2 y el modelo lineal simple del punto de rocío que tiene 0.61 como valor para el R^2. Mientras que tiene mayor error que cualquiera de los modelos de regresión lineal multiple que ninguno llega al 1.4 de error y todos tienen un 0.99 de R^2 .


No podemos comparar este algoritmo con el algoritmo de regresión lineal múltiple puesto que cada uno recibe una entrada distinta y se construye con un conjunto de variables 

####Comparación entre algoritmos (KNN y LM)
La verdad es que no se pueden comparar los dos algoritmos con los modelos que hemos creado hasta este punto puesto que ninguno tiene ni las mismas variables en el modelo ni los mismos ejemplos en la fase de entrenamiento y testeo. 
Por ello vamos a desarrollar un nuevo modelo lineal simple que al igual que el modelo obtenido por knn tenga todas las variables para la construcción del mismo y los mismos ejemplos para cada fase, o lo que es lo mismo que intervenga la validación cruzada. 

```{r}
run_lm_fold <- function(i,x,tt = "test"){
  file_n <- paste(x,"-5-",i, "tra.dat", sep = "")
  x_tra <- read.csv(file_n, comment.char = "@", header = FALSE)
  file <- paste(x,"-5-",i, "tst.dat", sep = "")
  x_tst <- read.csv(file, comment.char = "@")
  ln <- length(names(x_tra))-1
  names(x_tra)[1:ln] <- paste ("X", 1:ln, sep="")
  names(x_tra)[ln+1] <- "Y"
  names(x_tst)[1:ln] <- paste ("X", 1:ln, sep="")
  names(x_tst)[ln+1] <- "Y"
  if (tt == "train") {
    test <- x_tra
  }
  else {
    test <- x_tst
  }
  fitMulti=lm(Y~.,x_tra)
  yprime=predict(fitMulti,test)
  sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}
lmMSEtrain<-mean(sapply(1:5,run_lm_fold,nombre,"train"))
lmMSEtest<-mean(sapply(1:5,run_lm_fold,nombre,"test"))

lmMSEtrain
lmMSEtest
```

Con estos nuevos valores de error si que podemos comparar los dos algoritmos a nivel de error cometido. Podemos ver claramente que el error de entrenamiento es menor para el modelo de regresión lineal tanto para el entrenamiento como para el testeo que el obtenido por el modelo de knn, y en ambos casos con valores parecidos a los que obtuvimos para los modelos sin la valoración cruzada. 

###Comparación de algoritmos

Para hacer un test más fiable y cuantitativo que compare los algoritmos podemos realizar los test de Wilconxon,Friedman y Holm.

####Wilconxon
 El test de Wilconxon es un test no paramétrico con el que se comprueba que dos conjuntos de muestras son iguales y cuya hipótesis nula es que ambas muestras pertenecen a una misma distribución continua y simétrica respecto a una mediana que es igual a 0.
 
 Esta distribución se construye con la diferencia entre las dos muestras, las muestras son los errores cometidos en cada una de las particiones de la validación cruzada, tanto para la fase de entrenamiento como para la de test.
 
```{r}
collection_mse_train_lm = sapply(1:5,run_lm_fold,nombre,"train")
collection_mse_test_lm = sapply(1:5,run_lm_fold,nombre,"test")
collection_mse_train_knn = sapply(1:5,run_knn_fold,nombre,"train")
collection_mse_test_knn = sapply(1:5,run_knn_fold,nombre,"test")

collection_mse_lm = c(collection_mse_train_lm,collection_mse_test_lm)
collection_mse_knn = c(collection_mse_train_knn,collection_mse_test_knn)

differences =  collection_mse_lm - collection_mse_knn
wilconxon_diff =  cbind(
        ifelse(differences < 0, abs(differences)+0.1,0.1),
        ifelse(differences > 0, abs(differences)+0.1,0.1)
)

w1 = wilcox.test(collection_mse_lm,collection_mse_knn, alternative = "two.sided",paired = TRUE)
w2 = wilcox.test(collection_mse_knn,collection_mse_lm,alternative = "two.sided",paired = TRUE)

Rplus = w1$statistic
Rminus = w2$statistic
p_value = w1$p.value

c(Rplus, Rminus,p_value)
```
Puesto que el p-value es menor que 0.05, rechazamos la hipótesis nula de que ambos errores siguen la misma distribución, y, por tanto, de que los algoritmos sean igual de buenos. 

####Friedman

Podemos comparar tres muestras distintas, o lo que es lo mismo, la salida de tres algoritmos distintos si usamos el test de Friedman. El algoritmo que vamos a añadir a la lista es el modelo lineal de cinco regresores. Para poder compararlo usaremos también la validación cruzada sobre él.

```{r}
run_lmm_fold <- function(i,x,tt = "test"){
  file_n <- paste(x,"-5-",i, "tra.dat", sep = "")
  x_tra <- read.csv(file_n, comment.char = "@", header = FALSE)
  file <- paste(x,"-5-",i, "tst.dat", sep = "")
  x_tst <- read.csv(file, comment.char = "@")
  ln <- length(names(x_tra))-1
  names(x_tra)[1:ln] <- paste ("X", 1:ln, sep="")
  names(x_tra)[ln+1] <- "Y"
  names(x_tst)[1:ln] <- paste ("X", 1:ln, sep="")
  names(x_tst)[ln+1] <- "Y"
  if (tt == "train") {
    test <- x_tra
  }
  else {
    test <- x_tst
  }
  attach(x_tra)
  fitMulti=lm(Y~X1+X2+X3+X5+X7,x_tra)
  yprime=predict(fitMulti,test)
  sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}

collection_mse_train_lmm = sapply(1:5,run_lmm_fold,nombre,"train")
collection_mse_test_lmm = sapply(1:5,run_lmm_fold,nombre,"test")
collection_mse_lmm = c(collection_mse_train_lmm,collection_mse_test_lmm)

data = as.matrix(cbind(collection_mse_lm,collection_mse_knn,collection_mse_lmm))
friedman.test(data)
```
Dado que el valor del p-value es menor que 0.05, podemos decir que existe una diferencia significativa entre los tres conjuntos.

####Holms
Ahora que sabemos que existen diferencias entre los algoritmos vamos a realizar el test de Holms para ver entre que pares de algoritmos existen las diferencias.

```{r}
groups <- rep(1:dim(data)[2], each=dim(data)[1])
pairwise.wilcox.test(data, groups, p.adjust= "holm", paired = TRUE)
```

Existen diferencias significativas entre cualquier par de algoritmos al 95% de confianza.

```{r,echo=FALSE}
file_r = read.csv("./WizmirRegression/wizmir/regr_train_alumnos.csv",comment.char = "@")
file_r[18,] = c(lmMSEtrain,knnMSEtrain,lmMSEtrain)
write.csv(file_r,"./WizmirRegression/wizmir/regr_train_alumnos.csv")
file_r = read.csv("./WizmirRegression/wizmir/regr_test_alumnos.csv",comment.char = "@")
file_r[18,] = c(lmMSEtest,knnMSEtest,lmMSEtest)
write.csv(file_r,"./WizmirRegression/wizmir/regr_test_alumnos.csv")
```