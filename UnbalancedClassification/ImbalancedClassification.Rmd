---
title: "Clasificación no balanceada"
author: "Laura del Pino Díaz"
date: "5/2/2017"
header-includes: \usepackage[spanish]{babel}
output: pdf_document
toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width=60)
knitr::opts_chunk$set(comment = "", warning = FALSE, message = FALSE, echo = TRUE, tidy = TRUE, size="small")
```

# Clasificación no balanceada

La clasificación no balanceada se produce cuando queremos diferenciar al menos dos clases pero de una de ellas tenemos muy pocos ejemplos en comparación con las restantes clases.

##Objetivos

En esta práctica se persiguen los siguientes objetivos:
* Preparar los datos para la clasificación.
* Implementar la estrategia _Random Oversampling_ (ROS)
* Implementar la estrategia _Random Undersampling_ (RUS)
* Implementar la estrategia _Synthetic Minority Oversampli Technique_ (SMOTE)

##Carga de los conjuntos de datos

Los conjuntos de datos que vamos a utilizar en esta práctica son _sublus_ y _circle_. Se procede a su carga:

```{r}
subclus <- read.table("subclus.txt", sep=",")
colnames(subclus) <- c("Att1", "Att2", "Class")

circle <- read.table("circle.txt", sep = ",")
colnames(circle) <- c("Att1", "Att2", "Class")
```

##Estudio del desbalanceo

Descubrir  que un conjunto de datos está desbalanceado puede darse en la fase de visualización. Visualizamos las dos bases de datos:

```{r}
#subcluss
plot(subclus$Att1, subclus$Att2, main="Subcluss")
points(subclus[subclus$Class==0,1],subclus[subclus$Class==0,2],col="red")
points(subclus[subclus$Class==1,1],subclus[subclus$Class==1,2],col="blue")
```
Como podemos ver tenemos una clase minoritaria coloreada en rojo en medio de todo el espacio de puntos y con solapamiento entre esta clase y la mayoría. 

```{r}
plot(circle$Att1, circle$Att2, main="circle")
points(circle[circle$Class==0,1],circle[circle$Class==0,2],col="red")
points(circle[circle$Class==1,1],circle[circle$Class==1,2],col="blue")
```

En el caso de la base de datos _circle_ tenemos un problema más sencillo ya que no tenemos el problema añadido del solapamiento entre clases.

Medir el desbalanceo puede darnos una idea de cómo se distribuyen las clases en nuestro conjunto de datos. Una forma de representarlo es el índice de desbalanceo que procedemos a calcular:

```{r}
getIR = function(classData){
nClass0 <- sum(classData == 0)
nClass1 <- sum(classData == 1)
IR <- nClass1 / nClass0
IR 
}

IR_subcluss = getIR(subclus$Class)
IR_circle = getIR(circle$Class)

IR_subcluss
IR_circle
```

Como podemos ver la clase 1 en ambos casos es la mayoritaria, siendo en el caso de la base de datos _subcluss_ 5 veces mayor que la minoritaria y en el caso de la base de datos _circle_ 42.45 veces más abundante los ejemplos de la clase mayoritaria. 

##Clasificador de control

Ahora que conocemos como se comportan los conjuntos de datos, vamos a lanzar un clasificador que nos muestre la problemática de clasificar los dos conjuntos en el estado actual. 

Para mejorar las condiciones de entrenamiento del clasificador lo vamos a entrenar utilizando la técnica de validación cruzada de 5 particiones. Por ello creamos las particiones de cada conjunto de datos, respetando siempre el ratio de desbalanceo en cada una de las particiones. 

```{r}
#subcluss
pos <- (1:dim(subclus)[1])[subclus$Class==0]
neg <- (1:dim(subclus)[1])[subclus$Class==1]

SubclussCVperm_pos <- matrix(sample(pos,length(pos)), ncol=5, byrow=T)
SubclussCVperm_neg <- matrix(sample(neg,length(neg)), ncol=5, byrow=T)

SubclussCVperm <- rbind(SubclussCVperm_pos, SubclussCVperm_neg)

#circle

pos <- (1:dim(circle)[1])[circle$Class==0]
neg <- (1:dim(circle)[1])[circle$Class==1]

circleCVperm_pos <- matrix(sample(pos,length(pos)), ncol=5, byrow=T)
circleCVperm_neg <- matrix(sample(neg,length(neg)), ncol=5, byrow=T)

circleCVperm <- rbind(circleCVperm_pos, circleCVperm_neg)

```

Con las particiones preparadas entrenamos el clasificador

```{r}
library(class)
knn.pred = NULL
for( i in 1:5){
  predictions <- knn(subclus[-SubclussCVperm[,i], -3], subclus[SubclussCVperm[,i], -3], subclus[-SubclussCVperm[,i], 3], k = 3)
  knn.pred <- c(knn.pred, predictions)
}
acc <- sum((subclus$Class[as.vector(SubclussCVperm)] == 0 & knn.pred == 1) 
           | (subclus$Class[as.vector(SubclussCVperm)] == 1 & knn.pred == 2)) / (sum(subclus$Class == 0) + sum(subclus$Class == 1))
tpr <- sum(subclus$Class[as.vector(SubclussCVperm)] == 0 & knn.pred == 1) / sum(subclus$Class == 0)
tnr <- sum(subclus$Class[as.vector(SubclussCVperm)] == 1 & knn.pred == 2) / sum(subclus$Class == 1)
gmean <- sqrt(tpr * tnr)
gmean
```
 Como se muestra el clasificador tienen una alta tasa de acierto perteneciente prácticamente en su totalidad al acierto de la clase mayoritaria. De hecho se espera que para el conjunto de datos _circle_ sea  mayor puesto que la clase mayoritaria es aún más abundante. 
 
```{r}
knn.pred = NULL
for( i in 1:5){
  predictions <- knn(circle[-circleCVperm[,i], -3], circle[circleCVperm[,i], -3], circle[-circleCVperm[,i], 3], k = 3)
  knn.pred <- c(knn.pred, predictions)
}
acc <- sum((circle$Class[as.vector(circleCVperm)] == 0 & knn.pred == 1) 
           | (circle$Class[as.vector(circleCVperm)] == 1 & knn.pred == 2)) / (sum(circle$Class == 0) + sum(circle$Class == 1))
tpr <- sum(circle$Class[as.vector(circleCVperm)] == 0 & knn.pred == 1) / sum(circle$Class == 0)
tnr <- sum(circle$Class[as.vector(circleCVperm)] == 1 & knn.pred == 2) / sum(circle$Class == 1)
gmean <- sqrt(tpr * tnr)
gmean
```
Como se esperaba la tasa de acierto ha aumentado por el porcentaje de la clase mayoritaria, pero este crecimiento ha sido moderado puesto que la clase minoritaria no tiene solapamiento con la mayoritaria. 

#Random Oversampling (ROS)

La técnica _Random Oversampling_ toma los valores que ya existen de la clase minoritaria y genera nuevos ejemplos duplicando los existentes. Aplicaremos esta técnica a los dos conjuntos de datos que ya tenemos y compararemos la gmean en ambos casos con la obtenida en el caso de control. 

```{r}
knn.pred = NULL
for( i in 1:5){
  
  train <- subclus[-SubclussCVperm[,i], -3]
  classes.train <- subclus[-SubclussCVperm[,i], 3] 
  test  <- subclus[SubclussCVperm[,i], -3]
  
  # randomly oversample the minority class (class 0)
  minority.indices <- (1:dim(train)[1])[classes.train == 0]
  to.add <- dim(train)[1] - 2 * length(minority.indices)
  duplicate <- sample(minority.indices, to.add, replace = T)
  for( j in 1:length(duplicate)){
    train <- rbind(train, train[duplicate[j],])
    classes.train <- c(classes.train, 0)
  }  
  
  # use the modified training set to make predictions
  predictions <-  knn(train, test, classes.train, k = 3)
  knn.pred <- c(knn.pred, predictions)
}
tpr.ROS <- sum(subclus$Class[as.vector(SubclussCVperm)] == 0 & knn.pred == 1) / sum(subclus$Class == 0)
tnr.ROS <- sum(subclus$Class[as.vector(SubclussCVperm)] == 1 & knn.pred == 2) / sum(subclus$Class == 1)
gmean.ROS <- sqrt(tpr.ROS * tnr.ROS)
gmean.ROS
```
La gmean ha mejorado con respecto a la original aunque sigue manteniendo un margen de error debido al solapamiento entre clases.

```{r}
knn.pred = NULL
for( i in 1:5){
  
  train <- circle[-circleCVperm[,i], -3]
  classes.train <- circle[-circleCVperm[,i], 3] 
  test  <- circle[circleCVperm[,i], -3]
  
  # randomly oversample the minority class (class 0)
  minority.indices <- (1:dim(train)[1])[classes.train == 0]
  to.add <- dim(train)[1] - 2 * length(minority.indices)
  duplicate <- sample(minority.indices, to.add, replace = T)
  for( j in 1:length(duplicate)){
    train <- rbind(train, train[duplicate[j],])
    classes.train <- c(classes.train, 0)
  }  
  
  # use the modified training set to make predictions
  predictions <-  knn(train, test, classes.train, k = 3)
  knn.pred <- c(knn.pred, predictions)
}
tpr.ROS <- sum(circle$Class[as.vector(circleCVperm)] == 0 & knn.pred == 1) / sum(circle$Class == 0)
tnr.ROS <- sum(circle$Class[as.vector(circleCVperm)] == 1 & knn.pred == 2) / sum(circle$Class == 1)
gmean.ROS <- sqrt(tpr.ROS * tnr.ROS)
gmean.ROS
```

Al igual que en el caso anterior, la gmean ha mejorado al mejorar el balance de la clase minoritaria. 

#Random Undersampling (RUS)

La técnica de _Random Undersampling_ equilibra las dos clases mediante el borrado aleatorio de registros de la clase mayoritaria. Aplicaremos esta técnica a ambos conjuntos de datos y compararemos la gmean resultante con la obtenida en los dos apartados anteriores.

```{r}
knn.pred = NULL
for( i in 1:5){
  
  train <- subclus[-SubclussCVperm[,i], -3]
  classes.train <- subclus[-SubclussCVperm[,i], 3] 
  test  <- subclus[SubclussCVperm[,i], -3]
  
  # randomly undersample the minority class (class 1)
  majority.indices <- (1:dim(train)[1])[classes.train == 1]
  to.remove <- 2* length(majority.indices) - dim(train)[1]
  remove <- sample(majority.indices, to.remove, replace = F)
  train <- train[-remove,] 
  classes.train <- classes.train[-remove]
  
  # use the modified training set to make predictions
  predictions <-  knn(train, test, classes.train, k = 3)
  knn.pred <- c(knn.pred, predictions)
}
tpr.RUS <- sum(subclus$Class[as.vector(SubclussCVperm)] == 0 & knn.pred == 1) / sum(subclus$Class == 0)
tnr.RUS <- sum(subclus$Class[as.vector(SubclussCVperm)] == 1 & knn.pred == 2) / sum(subclus$Class == 1)
gmean.RUS <- sqrt(tpr.RUS * tnr.RUS)
gmean.RUS
```

Se ha obtenido un valor de gmean situado entre el obtenido en el clasificador de control y el de ROS, esto es debido a que al eliminar registros de la clase mayoritaria para igualar el número de observaciones de ambas clases ha perdido información sobre la clase mayoritaria. 

```{r}
knn.pred = NULL
for( i in 1:5){
  
  train <- circle[-circleCVperm[,i], -3]
  classes.train <- circle[-circleCVperm[,i], 3] 
  test  <- circle[circleCVperm[,i], -3]
  
  # randomly undersample the minority class (class 1)
  majority.indices <- (1:dim(train)[1])[classes.train == 1]
  to.remove <- 2* length(majority.indices) - dim(train)[1]
  remove <- sample(majority.indices, to.remove, replace = F)
  train <- train[-remove,] 
  classes.train <- classes.train[-remove]
  
  # use the modified training set to make predictions
  predictions <-  knn(train, test, classes.train, k = 3)
  knn.pred <- c(knn.pred, predictions)
}
tpr.RUS <- sum(circle$Class[as.vector(circleCVperm)] == 0 & knn.pred == 1) / sum(circle$Class == 0)
tnr.RUS <- sum(circle$Class[as.vector(circleCVperm)] == 1 & knn.pred == 2) / sum(circle$Class == 1)
gmean.RUS <- sqrt(tpr.RUS * tnr.RUS)
gmean.RUS
```

En este caso ha bajado ligeramente el valor de la gmean por el mismo motivo que en el caso anterior, porque pierde parte de la información de la clase mayoritaria, pero como en esta basa de datos los datos no están solapados esta diferencia no se nota demasiado. 