---
title: "California"
author: "Laura"
date: "3 de diciembre de 2016"
output:
  pdf_document: default
  toc: true
  theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width=60)
knitr::opts_chunk$set(comment = "", warning = FALSE, message = FALSE, echo = TRUE, tidy = TRUE, size="small")
```

## El conjunto de datos California
El conjunto de datos *California* contiene datos sobre viviendas de California y pretende estimar el precio de una nueva vivienda. 

Las variables con las que se pretende estimar el precio de la vivienda son las siguientes:

* Longitud (_longitude_)
* Latitud (_latitude_)
* La edad media de las casas (_HousingMedianAge_)
* El número de habitaciones (_TotalRooms_)
* El número de dormitorios (_TotalBedrooms_)
* El número de habitantes (_Population_)
* El número de unidades familiares en el edificio (_Households_)
* La media de ingresos (_MedianIncome_)
* El valor medio de la casa (_MedianHouseValue_). El valor de esta variable es la que pretendendemos obtener. 

##Hipótesis previas 
   
Sin mirar el contenido del conjunto de datos se plantean las siguientes hipótesis:

1. El número de habitaciones incrementa el precio de forma lineal.
2. A mayor edad meda más disminuye el precio.
3. A mayor población más incrementa el precio de la vivienda.
4. La distancia del centro disminuye el precio.
5. La media de ingresos hace aumenta el precio.
6. El número de unidades familiares en la vivienda hace disminuir el precio. 

##El conjunto de datos

La comprobación de las anteriores hipótesis la podemos realizar mirando como se comportan cada una de las variables con respecto a la salida. 

Para ello primero cargamos la base de datos
```{r}
california_original <- read.csv("california.dat", header = FALSE, comment.char = "@")
names(california_original) <- c("Longitude","Latitude","HousingMedianAge","TotalRooms","TotalBedrooms","Population","Households","MedianIncome","MedianHouseValue")

```
\newpage
Y mostramos las comparaciones con la salida de las variables anteriores

```{r}
plot(california_original$TotalRooms, california_original$MedianHouseValue, main = "Influencia del número de habitaciones en el precio", xlab = "Número de habitaciones", ylab = "Precio final")
```

Aparentemente no existe una relación lineal entre el número de habitaciones y el precio. 

\newpage
```{r}
plot(california_original$HousingMedianAge, california_original$MedianHouseValue, main = "Influencia de la edad en el precio", xlab = "Edad del inmueble", ylab = "Precio final")
```

Esta variable tampoco tiene una relación lineal como habíamos deducido. 

\newpage
```{r}
plot(california_original$Population, california_original$MedianHouseValue, main = "Influencia del número de habitates en el precio", xlab = "Número de habitantes", ylab = "Precio final")
```

Esta variable tampoco tiene una relación lineal con la salida, pero tiene una forma similar al gráfico del número de habitaciones. 

\newpage
Para calcular la distancia al centro como hemos planteado en la hipótesis 4 tenemos que calcular un centro. Pero antes de eso miremos como se comportan las variables longitud y latitud por separado con respecto de la salida.

```{r}
plot(california_original$Latitude, california_original$MedianHouseValue, main = "Influencia de la latitud en el precio", xlab = "Latitud", ylab = "Precio final")

plot(california_original$Longitude, california_original$MedianHouseValue, main = "Influencia de la longitud en el precio", xlab = "Longitud", ylab = "Precio final")
```

Claramente la relación latitud/longitud con el precio finla no es lineal, pero el hecho de que existan varios picos me hace pensar que puede haber varias ciudades con lo que calcular la media para establecerlo como centro no es una buena opción.

\newpage
```{r}
plot(california_original$MedianIncome, california_original$MedianHouseValue, main = "Influencia de la media de los ingresos en el precio", xlab = "Media de ingresos", ylab = "Precio final")
```

Puede ser una relación lineal con una dispersión muy alta, debido probablemente a la existencia de varias ciudades en el conjunto de datos.

Ya solo queda comprobar que al aumentar el número de unidades familiares disminuye el precio. 
\newpage 
```{r}
plot(california_original$Households, california_original$MedianHouseValue, main = "Influencia del número de unidades domésticas en el precio", xlab = "Unidades domésticas", ylab = "Precio final")
```

No sigue una distribución lineal pero por la forma que tiene la hipótesis de que a mayor número de unidades domésticas disminuye también es falsa. 


##Conclusiones sobre las hipótesis previas.

Tras ver la relación entre las variables de las hipótesis previas y la salida esperada,podemos llegar a las siguientes conclusiones:

* El conjunto de datos recoge varias ciudades.
* Al recoger varias ciudades las variables pueden presentar una tendencia lineal pero tener una amplia dispersión, relacionada con la ciudad en la que esté.
** Se debería clusterizar el conjunto de datos por ciudades.Pero el ejercicio es de modelos lineales por lo que no nos vamos a meter en la elaboración de clusters. Eso sí se espera que el modelo de regresión lineal sea bastante malo y que el modelo KNN presente mejores resultados. 
* La única variable estudiada hasta ahora que parece independiente de la ciudad es la media de ingresos. 

##Comparación de todas las variables con la salida

Ahora compararemos todas las variables con todas para tener una idea de las interacciones que pueden existir entre ellas. 

```{r}
attach(california_original)
pairs(california_original)

```

Las variables _TotalRooms_, _TotalBedrooms_, _Population_ y _Households_ tienen una relación lineal entre ellas. 


#Construcción del modelo lineal 
##Separación del conjunto de train

Para comenzar a elaborar los modelos predictivos necesitamos separar los datos en train y test. En esta primera parte del ejercicio vamos a coger el 60% del conjunto para el entrenamiento y el 40% restante para validación. 

```{r}
train <- california_original[1:(dim(california_original)[1]*0.6),]
test <- california_original[(dim(california_original)[1]*0.6):dim(california_original)[1],]

detach(california_original)
attach(train)
```

##Modelo lineal simple
Una vez conocemos como se comportan las variables podemos plantear un modelo lineal que aproxime una solución a nuestro problema. 

Podemos plantearlo como un modelo lineal de una sola variable, aunque sabemos que no va a ser un ajuste muy bueno pero de esta forma tendremos un parámetro de R^2 ajustada base para comparar más tarde. 

La variable que se usará para este modelo es _MedianIncome_ porque presentaba una tendencia lineal, más independiente que las demás estudiadas en el apartado anterior. 
```{r}
model1_singleLineal <- lm(MedianHouseValue~MedianIncome)
summary(model1_singleLineal)
```

El valor del parámetro R^2 es de **0.4681**, es bastante malo pero nos sirve como base para ir aumentando el número de variables que intervienen en el modelo de regresión lineal múltiple. 

##Modelo lineal múltiple

Las variables que vamos a añadir al modelo anterior serán _HouseHold, Population, TotalRooms,TotalBedRooms_ una a una comprobando siempre el coeficiente Rcuadrado para compararlo.

```{r}
model1_multipleLineal <- lm(MedianHouseValue~MedianIncome+Households)
summary(model1_multipleLineal)
```

    Al añadir la variable Household la variación  ha sido mínima en el modelo, ha pasado de 0.4681 a 0.4703. Aunque a partir de ahora deberemos fijarnos en el valor de R^2 ajustada ya que atiende al número de variables que se usan en el modelo. 
    Como las variables _Population, TotalRooms,TotalBedRooms_ tenían todas una gráfica similar a _Households_ vamos a probar a añadirlas todas a la vez. 
    

```{r}
model2_multipleLineal <- lm(MedianHouseValue~MedianIncome+Households+Population+TotalRooms+TotalBedrooms)
summary(model2_multipleLineal)
```

Añadir estas variables ha conseguido una mejora de casi un 0.5% del modelo. Puesto que sabemos que las variable anteriores probablemente dependen de la longitud y la latitud la incorporaremos dichas variables al modelo.

```{r}
model3_multipleLineal <- lm(MedianHouseValue~MedianIncome+Households+Population+TotalRooms+TotalBedrooms+Longitude+Latitude)
summary(model3_multipleLineal)
```

##Modelos con interacciones y polinomiales

Añadir las variables longitud y latitud al modelo ha supuesto una notable mejora al modelo, pero vamos a añadir una nueva variable que sea una interacción de la longitud y la latitud a ver si ayuda a mejorar el modelo.

```{r}
model4_multipleLineal <- lm(MedianHouseValue~MedianIncome+Households+Population+TotalRooms+TotalBedrooms+Longitude+Latitude+(Longitude*Latitude))
summary(model4_multipleLineal)
```

La mejora del modelo es mínima y además aparece la variable latitud como la menos significativa del conjunto.Dicha variable aunque la quitemos seguirá apareciendo porque tenemos el témino Longitud*Latitud que necesita de los términos de las dos componentes por separado, por ello se desarrollará un modelo por la vía polinomial.

Dado que las variables longitud y latitud visualizado con la gráfica adquieren una forma con varias cimas, podemos probar a utilizar el modelo anterior con polinomios sobre las variables latitud y longitud. 

Vamos a poner un polinomio de grado 10 en cada una de las variables para comprobar en que momento deja de ser interesante el miembro del polinomio.


```{r}
model5_multipleLineal <- lm(MedianHouseValue~MedianIncome+Households+Population+TotalRooms+TotalBedrooms+Longitude+Latitude+poly(Longitude,10)+poly(Latitude,10))
summary(model5_multipleLineal)
```

Un polinomio de grado 10 en las variables longitud y latitud tiene la gran mayoría de sus componentes como significativos para el ajuste de la función a los datos. Pero hay algunos miembros como el de grado 3 en la variable latitud y el de grado 9 y 3 para la variable longitud que aparecen como nad significativas. Por esto y por simplicidad se va a regresar a la versión anterior del modelo.

Aún podemos probar a elaborar un modelo polinómico en el que la variable sea la interacción entre la latitud y la longitud. Y al igual que en el modelo anterior vamos a realizar la prueba poniendo un polinomio de grado muy alto para ver la significatividad que tendrían cada uno de los polinomios.

```{r}
model6_multipleLineal <- lm(MedianHouseValue~MedianIncome+Households+Population+TotalRooms+TotalBedrooms+Longitude+Latitude+poly(Longitude*Latitude,10))
summary(model6_multipleLineal)
```

El modelo mejora, poco pero mejora. Puesto que no todos los miembros del polinomio tienen un nivel de significación suficiente se probará con modelos donde el polinomio sea menor. 

```{r}
model7_multipleLineal <- lm(MedianHouseValue~MedianIncome+Households+Population+TotalRooms+TotalBedrooms+Longitude+Latitude+poly(Longitude*Latitude,5))
summary(model7_multipleLineal)
```

Aún aparece el miembro de grado 3 como poco significativo por lo que vamos a reducir el grado del polinomio a 3, aprovechando que solamente se perdieron unas centésimas en el valor de R^2. 

```{r}
model8_multipleLineal <- lm(MedianHouseValue~MedianIncome+Households+Population+TotalRooms+TotalBedrooms+Longitude+Latitude+poly(Longitude*Latitude,3))
summary(model8_multipleLineal)
```

No ha sido una buena idea puesto que se ha perdido un 0.2 en el valor de R^2, sin embargo este nuevo valor de R^2 es similar a la del modelo 3 que era mucho más simple y sencillo de explicar. 

Por tanto es con este modelo 3 con el que vamos a realizar las pruebas con el conjunto de test.

##Predicción de valores

   Ahora que tenemos escogido el modelo lo probaremos sobre el conjunto de datos que hemos apartado como conjunto de test.
   
```{r}
yprime <- predict(model4_multipleLineal,test)
sqrt(sum(abs(test$MedianHouseValue-yprime)^2)/length(yprime))
```

Lo que nos devuelve la última llamada es el _root-mean-square-error(RMSE)_ también conocido como la raíz del error cuadrático medio, similar a la desviación standar de la predicción. 

El valor anterior es semejante a la décima parte del valor máximo que puede tomar el valor de las casas. Pero es el mejor modelo lineal que hemos obtenido. 

##Explicación del modelo lineal

En el modelo lineal escogido intervienen todas las variables registradas, es decir, en el precio final de una vivienda interviene la media de los ingresos de la zona, el número de unidades domésticas en el inmueble, el número de habitantes, el número total de habitaciones y de dormitorios así como la ciudad en la que está que se descompone en longitud y latitud. 

#Regresión usando KNN

La técnica de los k-vecinos más cercanos nos permite crear devolver un valor de predicción basándonos en los datos ya existentes.

##Paquetes necesarios

Para utilizar la técnica del vecino más cercano tenemos que utilizar funciones de la librería knn y MASS por lo que le indicamos a R que las necesitamod

```{r}
require("MASS")
require("kknn")
```

##Creando el modelo

Ahora para crear el modelo realizamos la llamada a la funcion knn con la base de datos de california completa. 

En este caso el número de vecinos más cercanos que se escogerán será de 7 y la distancia euclídea y se realizará el escalado de los datos para que tengan todos el mismo rango de valores. 

```{r}
fitknn1 <- kknn(california_original$MedianHouseValue ~ ., california_original,california_original)

```

Este nuevo modelo tendrá en su componente "fitted.values" los valores obtenidos en la fase de test. 

Antes de calcular su bondad vamos a visualizar los resultados.

```{r}
plot(california_original$MedianHouseValue~california_original$MedianIncome)
points(california_original$MedianIncome,fitknn1$fitted.values,col="blue",pch=20)
```

No es un modelo perfecto pero es bastante bueno. Para compararlo con el mejr de los lineales vamos a calcular el RMSE

```{r}
yprime_2 = fitknn1$fitted.values
sqrt(sum((california_original$MedianHouseValue - yprime_2)^2)/length(yprime_2))
```
Como podemos ver el RMSE es significativamente menor que el obtenido por el considerado el mejor modelo de regression lineal múltiple, que tenía  de ,valor RMSE 71274.62

Comprobemos que este error sigue bajando si le ponemos un modelo semejante al que desarrollamos con el modelo lineal múltiple si añadimos polinomios de un grado superior, en este caso vamos a añadir un polinomo de grado 3 y de grado 5 para ver la evolución del error. 

```{r}
fitknn2 <-kknn(california_original$MedianHouseValue ~ . + poly(california_original$Latitude*california_original$Longitude,3), california_original,california_original)
yprime_3 = fitknn2$fitted.values
sqrt(sum((california_original$MedianHouseValue - yprime_3)^2)/length(yprime_3))
```

```{r}
fitknn3 <-kknn(california_original$MedianHouseValue ~ . + poly(california_original$Latitude*california_original$Longitude,5), california_original,california_original)
yprime_4 = fitknn3$fitted.values
sqrt(sum((california_original$MedianHouseValue - yprime_4)^2)/length(yprime_4))
```

Vemos en los resultados anteriores que al igual que los modelos homólogos del apartado anterior podemos ver una mejora del error.Pero mejor ilustrarlo con un gráfico:
```{r}
plot(california_original$MedianHouseValue ~ california_original$MedianIncome, pch = 20 , main = "Comparación entre modelos Knn")

points(california_original$MedianIncome, fitknn1$fitted.values, col="red",pch = 20)
points(california_original$MedianIncome, fitknn2$fitted.values, col="green",pch = 20)
points(california_original$MedianIncome, fitknn3$fitted.values, col="orange",pch = 20)

```

En color negro tenemos los datos originales, en rojo el primer modelo creado en el que solo intervienen todas las variables sin ningún tipo de no linealidad, en color verde tenemos el mismo modelo con un polinomio de grado 3 para la combinación de longitud y latitud y en naranja el modelo anterior pero de grado 5.

En todos los casos los modelos parecen bastante buenos, pero ninguno de ellos recogen los valores de la parte superior izquierda de la gráfica ni los de la parte inferior izquierda y les cuesta acertar con los valores dispersos del lado derecho. 

El modelo con el polinomio de grado 5, tiene un menor error, pero por simplicidad nos quedamos con el modelo que no tiene ningún tipo de polinomio de grado superior a 2 en el modelo. 

#Validación cruzada 

Para comprobar lo bueno que es nuestro modelo tenemos que comprobar su capacidad de generalizar para ello utilizaremos la  validación cruzada. 

Este método requiere tener los datos divididos en k partes y calcular el error medio de forma que el error real sea la media de todos los errores de las partes utilizadas como unidad de test. 

Como los datos ya los tenemos en ficheros separados lo que vamos a realizar es lectura de los mismos y a calcular el error cuadrática medio de los modelos propuestos. 

```{r}
nombre <- "california"
run_lm_fold <- function(i,x,tt = "test"){
  file_n <- paste(x,"-5-",i, "tra.dat", sep = "")
  x_tra <- read.csv(file_n, comment.char = "@", header = FALSE)
  file <- paste(x,"-5-",i, "tst.dat", sep = "")
  x_tst <- read.csv(file, comment.char = "@")
  ln <- length(names(x_tra))-1
  names(x_tra)[1:ln] <- paste ("X", 1:ln, sep="")
  names(x_tra)[ln+1] <- "Y"
  names(x_tst)[1:ln] <- paste ("X", 1:ln, sep="")
  names(x_tst)[ln+1] <- "Y"
  if (tt == "train") {
    test <- x_tra
  }
  else {
    test <- x_tst
  }
  fitMulti=lm(Y~.,x_tra)
  yprime=predict(fitMulti,test)
  sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}
lmMSEtrain<-mean(sapply(1:5,run_lm_fold,nombre,"train"))
lmMSEtest<-mean(sapply(1:5,run_lm_fold,nombre,"test"))

lmMSEtrain
lmMSEtest
```

En este caso el error es mayor en el test que en el entrenamiento por lo que el modelo no generaliza bien. 

Si construimos la misma estructura para probarlo con el algoritmo knn

```{r}
nombre <- "california"
run_knn_fold <- function(i, x, tt = "test") {
  file <- paste(x, "-5-", i, "tra.dat", sep="")
  x_tra <- read.csv(file, comment.char="@")
  file <- paste(x, "-5-", i, "tst.dat", sep="")
  x_tst <- read.csv(file, comment.char="@")
  In <- length(names(x_tra)) - 1
  names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
  names(x_tra)[In+1] <- "Y"
  names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
  names(x_tst)[In+1] <- "Y"
  if (tt == "train") {
    test <- x_tra
  }
  else {
    test <- x_tst
  }
  fitMulti<- kknn(Y~.,x_tra,test)
  yprime=fitMulti$fitted.values
  sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}
knnMSEtrain<-mean(sapply(1:5,run_knn_fold,nombre,"train"))
knnMSEtest<-mean(sapply(1:5,run_knn_fold,nombre,"test"))
knnMSEtrain
knnMSEtest
```

Vemos que tiene mucho menos error en la fase de generalización que el modelo de regresión múltiple. 

