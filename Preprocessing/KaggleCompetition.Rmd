---
title: "PreprocesamientoKaggle"
author: "Laura del Pino Díaz"
date: "13/2/2017"
header-includes: \usepackage[spanish]{babel}
output: pdf_document
toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width=60)
knitr::opts_chunk$set(comment = "", warning = FALSE, message = FALSE, echo = TRUE, tidy = TRUE, size="small")
```
\newpage

#Preprocesamiento y clasificación

##Objetivo del proyecto

El objetivo de este proyecto es clasificar lo más correctamente posible los accidentes de tráfico recogidos en la base de datos. Para ello tendremos que aplicar los conocimientos obtenidos sobre preprocesamiento y las distintas técnicas de clasificación aprendidas, de forma que no nos quedemos con un modelo único de clasificación, sino que vayamos iterando sobre uno inicial y mejorándolo en cada iteración. 

##La base de datos
La base de datos está divida en datos de entrenamiento y datos de test. Los datos de entrenamiento recogen 30002 instancias de 30 variables con la variable clase asignada, mientras que la partición de test contiene 19998 instancias y carece de la variable con la etiqueta asignada. 

```{r}
train  = read.csv("accidentes-kaggle.csv")
test = read.csv("accidentes-kaggle-test.csv")
```

##El formato de salida
El formato de salida será un fichero .csv en el que se muestra el identificador de la instancia y su valor de salida.

Como prueba de como funciona el envío a la plataforma Kaggle vamos a crear un fichero .csv que tiene el número de registros requeridos y una etiqueta 

```{r}
id = 1:19998
Prediction = rep(factor("Atropello"), 19998)
outputDataset = data.frame(id,Prediction)
write.table(outputDataset, file = "./Output.csv", sep = ",",row.names = FALSE)
```

Para facilitar la salida de los sucesivos ficheros de salida vamos a crear la siguiente función _ToFile_ al que se le pasa las predicciones para que las imprima.

```{r}
ToFile = function(Prediction,fileTitle = "Output.csv"){
Id = 1:19998
outputDataset = data.frame(Id,Prediction)
write.table(outputDataset, file = fileTitle, sep = ",",row.names = FALSE)
}
```

##Análisis de datos
Antes de desarrollar ningún tipo de modelo de clasificación debemos saber como está estructurada nuestra base de datos. Para ello miramos los tipos de datos:

```{r}
str(train)
```

La gran mayoría de las variables son categóricas representadas con factores de distintos niveles. El que llama la atención es la variable _HORA_ que tiene valores numéricos que se han interpretado como factores. Eso lo corregimos con la siguiente función. 

```{r}
train$HORA = as.numeric(as.character(train$HORA))
test$HORA = as.numeric(as.character(test$HORA))
```

###Análisis de valores perdidos
En la función _str_ también podemos ver que algunas variables presentan valores perdidos. Por lo que resultaría interesante saber el procentaje de estos valores perdidos.

```{r}
apply(train, 2, function(col)sum(is.na(col))/length(col))
```

Ante el alto porcentaje de valores perdidos de la variable ACOND_CALZADA, podríamos pensar que esta variable no contribuye a la clasificación, pero podríamos perder una variable que clasifique bien algún tipo de clase. Para probar esta hipótesis vamos a coger todos aquellos valores que no están perdidos y mirar la diversidad de clases que tiene asociadas. 

```{r}
levels(as.factor(train[which(is.na(train$ACOND_CALZADA)), "TIPO_ACCIDENTE"]))
```
 Como vemos salen todos los niveles posibles, por lo que no favorece la clasificación de ninguna clase, con lo que gana votos para ser eliminado ante una selección de características. 
 
###Estudio de los estadísticos principales.

Una aproximación al comportamiento de las variables con las que estamos trabajando son los valores de los estadísticos principales, es decir, de la media, mediana,cuartiles en conjunto con el valor máximo y mínimo. En el caso de las variables no numéricas, es decir, todas aquellas que son categóricas lo que obtendremos es una relación de los valores más frecuentes con dicha frecuencia. 


```{r}
summary(train)
```

En el caso de la variable _TOTVICTIMAS_ vemos que la gran mayoría de los registros tienen el valor 1 hasta el tercer cuartil, puede ser una variable decisiva en algún arbol de desición, para distinguir entre algunas clases o por el contrario no aportar información en la gran mayoría de los casos. 
Como esta variable, las variables _TOTMUERTOS_, _TOTHERIDOSGRAVES_ no varían su valor hasta pasado el tercer cuartil. 
Las restantes variables numéricas tienen un comportamiento similar, pero su valor si se modifica antes del tercer cuartil. 
Si nos fijamos el el valor máximo, de las variables numérticas, tenemos que difieren significativamente, tanto que ante un test de distancia intercuartil para la determinación de anomalías, todos ellos saldrían como anomalías. No vamos a eliminar los registros con dichos valores porque se puede dar el caso de que sean anomalías en esta variable pero en combinación con otras variables sea un valor _"normal"_ .

Veámoslo en un boxplot:

```{r}
library(graphics)
boxplot(train[,8:12],use.cols=TRUE,las = 2)
```

###Estudio de la correlación

De estas variables continuas podemos estudiar la correlación entre ellas. 

```{r}
cor(train[,8:12])
```

Se puede observar que el número de víctimas y el número de heridos leves está muy correlado, de hecho el 87% de los casos de uno se explician con el otro. Si este porcentaje  fuese mayor me plantearía eliminar una de las dos, por ahora eliminarlo solo quedaría si necesitase entrenar un modelo y por el volumen de datos su aprendizaje fuese lento. 

###Relaciones de las variables con la salida

Todos los pasos anteriores se han concentrado en las variables numéricas, obviando la existencia de las variables categóricas. En este punto del análisis de datos vamos a estudiar cómo se relacionan con la salida. 

```{r}

plot(train[,c(-1,-3-8,-9,-10,-11,-12)])
```

#Aproximación 1: árbol de desición. 

 Como primera aproximación vamos a utilizar un modelo de árbol de desición. Uno de los modelos más robustos ante anomalías.  Para este caso vamos a determinar que ignore todos aquellos valores perdidos. 
 
```{r}
library(tree)
train2 = train[,c(-5,-15)] #Se eliminan aquellas variables que generan problemas con el algoritmo tree.
test2 = test[,c(-5,-15)]
test2$HORA = as.numeric(test2$HORA)
treeModel = tree(TIPO_ACCIDENTE~., train2)
treePredictions = predict(treeModel,test2,type = "class")
ToFile(treePredictions,"TreeTest.csv")
```

El resultado obtenido por este modelo ha sido 0.81832

#Aproximación 1b: árbol de decisión con selección de características.

Del análisis previo tenemos la variable ACOND_CALZADA como variable que no aporta mucha informaición ya que en el 78% de sus valores están perdidos y el resto de las instancias  pueden corresponde con alguna de las seis clases, por lo que no ayuda en la clasificación. En esta aproximación quiero desarrollar un modelo del tipo árbol, eliminando esta variable y comprobar si da un resultado igual al anterior. 

```{r}
test3 = test2[,-18]
train3 = train2[,-18]
treeModel = tree(TIPO_ACCIDENTE~., train3)
treePredictions = predict(treeModel,test3,type = "class")
ToFile(treePredictions,"TreeTest2.csv")
```

Este modelo ha obtenido una ligera mejora con respecto con el anterior: 0.00059 teniendo una puntuación final de 0.81891.

#Aproximación 1b2: árbol de decisión con selección de características y imputación de valores. 

En los anteriores modelos hemos ignorardo los valores perdidos en la construcción del modelo. En esta variante vamos a realizar una imputación de valores. 
```{r}
library(mice)

#imputedData = mice(train, m=5, method = "pmm") Comentado para que no se ejecute en llamadas sucesivas de Rmarkdown dado que tarda un día en terminar su ejecución
#trainImputed = complete(imputedData)
#write.csv(trainImputed,"./imputedData.csv") <-data set con los valores imputados en la primera ejecución de mice.
```
Comprobemos que los porcentajes de valores perdidos se han reducido tras la imputación
```{r}
originalNAs = apply(train, 2, function(col)sum(is.na(col))/length(col)) 
imputedNAs = apply(trainImputed, 2, function(col)sum(is.na(col))/length(col))
data.frame(originalNAs,imputedNAs)
```

Podemos ver que no tenemos ningún valor perdido. Ahora entrenamos otra estructura de tipo árbol con esta nueva base de datos. 

```{r}
treeModel = tree(TIPO_ACCIDENTE~.-ACOND_CALZADA, (trainImputed[,c(-5,-15,-18)]))
treePredictions = predict(treeModel,test2,type = "class")
ToFile(treePredictions,"TreeTest2.csv")
```

Este modelo en la clasificación a obtenido una puntuación de 0.81891 lo que no es una mejora con respecto al método anterior. Esto también se puede leer como la ausencia de valores y la imputación de los mismos hace el mismo efecto, por lo que a partir de ahora vamos a proseguir con árboles de desición con el dataset completo para evitar problemas de característ. 

#Aproximación 1c: Random forest

TODO: hacer una intro de random forest

```{r}
library(randomForest)
library(mice)

subsetTrainImputed = trainImputed[,c(-7,-15,-29)]
RFModel = randomForest( TIPO_ACCIDENTE~.,data = subsetTrainImputed)
test4 = test[,c(-7,-15,-29)]
RFPredictions = predict(RFModel,test4)
ToFile(RFPredictions,"RandomForest.csv")
```

Si visualizamos el archivo, nos encontramos con que la infinita mayoría de los valores se han determinado como valores perdidos, por lo que no testeamos este modelo en la plataforma Kaggle. 

#Aproximación 1c2: Randomforest con valores imputados en el conjunto de test

```{r}
test4Imputed = complete(mice(test4, method = "pmm",m=1))
RFModel = randomForest( TIPO_ACCIDENTE~.,data = subsetTrainImputed)
iRFPredictions = predict(RFModel,test4Imputed)
ToFile(iRFPredictions,"iRandomForest.csv")
```

0.82938 	

#Aproximación 1c3: RandomForest con un mayor número de árboles y con valores imputados en el conjunto de test

##600 árboles

```{r}

RFModel2 = randomForest( TIPO_ACCIDENTE~.,data = subsetTrainImputed, ntree=600)
iRFPredictions = predict(RFModel2,test4Imputed)
ToFile(iRFPredictions,"it600RandomForest.csv")
```

0.82988

##1000 árboles

```{r}
RFModel2 = randomForest( TIPO_ACCIDENTE~.,data = subsetTrainImputed, ntree=1000)
iRFPredictions = predict(RFModel2,test4Imputed)
ToFile(iRFPredictions,"it1000RandomForest.csv")
```

0.82918 añadir más árboles no implica una mejoría. 

##Nodos terminales mínimos = 6

```{r}
RFModel3 = randomForest( TIPO_ACCIDENTE~.,data = subsetTrainImputed,ntree=600,nodesize=6)
iRFPredictions = predict(RFModel3,test4Imputed)
ToFile(iRFPredictions,"i600n6RandomForest.csv")
```

#Aproximación 2: Boosting

```{r}
library(adabag)
library(caret)

#BoostingModel = adabag::boosting(TIPO_ACCIDENTE~.,data = subsetTrainImputed,mfinal = 10,control = rpart::rpart.control(maxdepth =2))
```

No se realizó este experimento porque su tiempo de ejecución.

#Aproximación 3: Datos balanceados por duplicidad.

Un aspecto de los datos que no contemplamos en el análisis previo de los datos es el desbalanceo de las clases. 

```{r}
lvls = levels(trainImputed[,"TIPO_ACCIDENTE"])
clss = c()
for (i in 1:length(lvls)){
  clss = c( clss, sum(trainImputed == lvls[i])/(dim(trainImputed)[1]))
}

clss
```

Como podemos hay un desbalanceo de carga importante dado que una clase representa más de la mitad de las instancias y las otras comparten el espacio restante. Esto supone un problema dado que los modelos probados hasta ahora son sensibles a los casos desbalanceados.

Para corregir esta situación vamos a utilizar dos técnicas de balanceo de carga: la duplicación de registros de cada clase hasta que todos compartan el mismo porcentaje y SMOTE.

En esta primera aproximación a la igualación de carga esperamos que el modelo se sobreajuste a los datos por lo que tenga menor capacidad de generalización con la consecuente falta de test.

```{r}
lvls = levels(trainImputed[,"TIPO_ACCIDENTE"])
instances = c()
for (i in 1:length(lvls)){
  instances = c( instances, sum(trainImputed == lvls[i]))
}

instances

maxInstances = max(instances)
maxInstances

extendedTrainImputed = trainImputed

for(c in 1:length(lvls)){
  
  #Tomar el subconjunto de instancias que coincide con el tipo de accidentes
  trainOfClassSubset = subset(trainImputed,TIPO_ACCIDENTE == lvls[c]) #???
  
  
  subsetCount = dim(trainOfClassSubset)[1]
  subsetCount
  while(subsetCount < maxInstances){
      randSample = sample(trainOfClassSubset,30)
    extendedTrainImputed = rbind(extendedTrainImputed,randSample)
    subsetCount = subsetCount + (dim(randSample)[1]) 
  }
}
```


```{r}
clss = c()
for (i in 1:length(lvls)){
  clss = c( clss, sum(extendedTrainImputed == lvls[i])/(dim(extendedTrainImputed)[1]))
}

clss
```


##3a: Duplicidad de registros con el mejor RandomForest

```{r}
duplicitySubset = extendedTrainImputed[,c(-7,-15,-29)]
rfDuplicityModel = randomForest(TIPO_ACCIDENTE~.,data = duplicitySubset,ntree=600,nodesize=6)
isRFPredictions = predict(rfDuplicityModel,test4Imputed)
ToFile(isRFPredictions,"i600n6DuplicityRandomForest.csv")
```

0.82889,

##3b: Duplicidad de registros con C4.5

```{r}
treeModel2 = tree(TIPO_ACCIDENTE~.-ACOND_CALZADA, duplicitySubset[,c(-5)])
treePredictions = predict(treeModel2,test4Imputed,type = "class")
ToFile(treePredictions,"DuplicityTreeTest.csv")
```

0.81891

#Aproximación 4: Smote para el balanceo de las clases

```{r}
library(DMwR)
smotedData = SMOTE(TIPO_ACCIDENTE~.,trainImputed)
smotedTrain = rbind(trainImputed,smotedData)
```

## 4a: SMOTE con el mejor de los Random Forest

```{r}
smotedSubset = smotedTrain[,c(-7,-15,-29)]
rfsmotedModel = randomForest(TIPO_ACCIDENTE~.,data = smotedSubset,ntree=600,nodesize=6)
isRFPredictions = predict(rfsmotedModel,test4Imputed)
ToFile(isRFPredictions,"i600n6SMOTERandomForest.csv")
```

0.82829

## 4b SMOTE con k = 7

```{r}
smotedData = SMOTE(TIPO_ACCIDENTE~.,trainImputed, k = 7)
smotedTrain = rbind(trainImputed,smotedData)
smotedSubset = smotedTrain[,c(-7,-15,-29)]
rfsmotedModel = randomForest(TIPO_ACCIDENTE~.,data = smotedSubset,ntree=600,nodesize=6)
isRFPredictions = predict(rfsmotedModel,test4Imputed)
ToFile(isRFPredictions,"i600n6SMOTEk7RandomForest.csv")
```

0.82829

## 4c SMOTE con k = 3

```{r}
smotedData = SMOTE(TIPO_ACCIDENTE~.,trainImputed, k = 3)
smotedTrain = rbind(trainImputed,smotedData)
smotedSubset = smotedTrain[,c(-7,-15,-29)]
rfsmotedModel = randomForest(TIPO_ACCIDENTE~.,data = smotedSubset,ntree=600,nodesize=6)
isRFPredictions = predict(rfsmotedModel,test4Imputed)
ToFile(isRFPredictions,"i600n6SMOTEk3RandomForest.csv")
```

0.82790


#Aproximación 5: Selección de características cuantitativa

En ejemplos anteriores hemos realizado una selección de características basándonos en el número de valores perdidos que tenía cierta variable o en que el método pudiera ejecutarse correctamente. 

En este apartado realizaremos comprobaciones cuantitativas para la selección de características, basándonos en la utilización del paquete FSelector.

Lo primero en lo que nos fijamos a la hora de utilizar un método de selección de características es que nos permita realizar el experimento con las variables _en su estado natural_ , es decir, si son numéricas, se trabaja con numéricas y si son factores se trabaja con factores. 

Los experimentos realizados con los métodos de selección de características son los siguientes:

OneR, este método basado en reglas de asociación calcula el peso generando reglas que tengan un solo término en el antecedente:
```{r}
library(mlbench)
library(FSelector)

weight = FSelector::oneR(TIPO_ACCIDENTE~.,trainImputed)
subsetW = cutoff.k(weight,5)
f1 = as.simple.formula(subsetW, "TIPO_ACCIDENTE")
print(f1)
```

De este selector obtenemos que la variable de salida _TIPO ACCIDENTE_ viene terminada principalmente por el año, el total de vehículos implicados, las aceras, la densidad de circulación y la zona agrupada. 


Para seleccionar las características por la independencia que muestran sobre la variable de salida utilizamos el test de la _chi cuadrado_

```{r}

weight = FSelector::chi.squared(TIPO_ACCIDENTE~.,trainImputed)
subsetW = cutoff.k(weight,5)
f2 = as.simple.formula(subsetW, "TIPO_ACCIDENTE")
print(f2)
```

Tenemos como resultado que las variables de las que más depende la salida son: el total de vehículos implicados, la zona agrupada, la carretera la zona y las aceras. 

Para saber que variables son las que nos aporta más ganancia de información realizamos el siguiente experimento:
```{r}

weight = FSelector::information.gain(TIPO_ACCIDENTE~.,trainImputed)
subsetW = cutoff.k(weight,5)
f3 = as.simple.formula(subsetW, "TIPO_ACCIDENTE")
print(f3)
```

Los anteriores experimentos no tienen todos el mismo resultado dado que usan métricas distintas. Para obtener un resultado común utilizaremos el método _cfs_ que combina ambas métricas. 

```{r}

subset2 = FSelector::cfs(TIPO_ACCIDENTE~.,trainImputed)
f4 = as.simple.formula(subset2,"TIPO_ACCIDENTE")
print(f4)
```

Este método nos devuelve una de las variables que ha aparecido en todas las salidas anteriores. 

Dado que utilizar una única variable, me parece poco apropiado para realizar la clasificación utilizaré otra métrica más: la consistencia. 

```{r}
subset2 = consistency(TIPO_ACCIDENTE~.,trainImputed)
f = as.simple.formula(subset2,"TIPO_ACCIDENTE")
print(f)
```

##5a - Random Forest con selección de características: consistencia y cfs

Consistencia no se puede usar porque RF no permite usar más de 53 etiquetas y tenemos provincia que si las tiene. 

cfs
```{r}
rffsModel = randomForest(f4, trainImputed[,c(-5)])
rffsPredictions = predict(rffsModel,test4Imputed)
ToFile(rffsPredictions,"randomForestFeatureSelectionConsistency.csv")

```
0.73246

##5b - Random forest con selección de características: oneR

```{r}
rffs2Model = randomForest(f1, trainImputed[,c(-5)])
rffsPredictions2 = predict(rffs2Model,test4Imputed)
ToFile(rffsPredictions2,"randomForestFeatureSelectionOneR.csv")

```

0.81901

Ninguna de las otras fórmulas permite discriminar usando Random Forest por usar la variable Carretera que tiene más de 53 categorías. 


#Aproximación 6: Preprocesamiento semántico

Del apartado anterior obtenemos que la segunda variable que más discrimina es CARRETERA, dado que aparece en todas las fórmulas, menos en dos de ellas que son las que se vieron en el apartado anterior. 

Esta variable contiene el nombre de la carretera, compuesto normalmente por una abreviatura de provincia o comunidad y un número. Dado que en españa hay 52 provincias y  18 ciudades autónomas, la combinación de las abreviaturas de estas con dígitos de 3 cifras hace que las combinatoria para obtener el número de factores se dispare hasta los cerca de 3000 niveles que tenemos. 

La carretera no podemos defirla solamente con esta variable sino que tenemos que apoyarnos en las variables RED_CARRETERA Y TIPO_VÍA.

Si fijamos en los niveles de TIPO_VÍA tenemos un nivel que es OTRO_TIPO que semáticamente se puede interpretar como un valor perdido. 

```{r}
sum(trainImputed$TIPO_VIA == "OTRO TIPO") / (dim(trainImputed)[1])
```
 Y como podemos ver, representa la mitad de los valores de esta variable. 
 
 Si tomamos el sistema de nomenclatura de carreteras de Wikipedia podemos completar estos datos.
 
 Como primer paso tenemos que separar los dos componentes del nombre de la carretera. 
 
```{r}
carreteraCHR = as.character(trainImputed$CARRETERA)
carreteraCHR2 = lapply(carreteraCHR,function (x) strsplit(x,"-"))
carreteraLetras = as.character(lapply(carreteraCHR2,function(x) return(x[[1]][1])))
carreteraNumero = as.character(lapply(carreteraCHR2,function(x) return(x[[1]][2])))
```


Antes de continuar nos conviene saber que otros valores tiene la variable TIPO_VÍA

```{r}
levels(trainImputed$TIPO_VIA)
```


Ahora crearemos una "base de conocimiento" con la que vamos a completar los valores que determinados como "OTRO TIPO".

```{r}
for( i in 1:(dim(trainImputed)[1])){
  if(trainImputed[i,17] == "OTRO TIPO"){
    #print(i)
    if(carreteraLetras[i] == "AP"){ #Autopista con peaje, la englobamos en autopista
      trainImputed[i,17] = "AUTOPISTA"

    }
    else if(carreteraLetras[i] == "A"){ #Autopistas libres y autovías
      trainImputed[i,17] = "AUTOVIA"
      
    }
    else if(carreteraLetras[i] == "N"){ #Carreteras nacionales y de doble calzada
      trainImputed[i,17] = "VIA CONVENCIONAL"
      
    }
    else if(length(carreteraLetras[i]) == 2 && length(carreteraNumero) == 2 ){ #Puede ser cualquier tipo de carretera, depende del número de cifras.
      trainImputed[i,17] = "AUTOVIA"
      
    }
    else if(length(carreteraLetras[i]) == 2 && length(carreteraNumero) == 4 ){ #Puede ser cualquier tipo de carretera, depende del número de cifras.
      trainImputed[i,17] = "CAMINO VECINAL"
    }
    else{
      trainImputed[i,17] = "VIA CONVENCIONAL"
    }
  }
}
```


```{r}
sum(trainImputed$TIPO_VIA == "OTRO TIPO") / (dim(trainImputed)[1])
```

si ahora los 

```{r}
weight = FSelector::information.gain(TIPO_ACCIDENTE~.-CARRETERA,trainImputed)
subsetW = cutoff.k(weight,5)
f3 = as.simple.formula(subsetW, "TIPO_ACCIDENTE")
print(f3)
```


```{r}
rffs2Model = randomForest(f1, trainImputed[,c(-5)])
rffsPredictions2 = predict(rffs2Model,test4Imputed)
ToFile(rffsPredictions2,"randomForestFeatureSelectionOneRCompleteImputed.csv")

```

0.81901

```{r}
rffs2Model = randomForest(f1, trainImputed[,c(-5)],ntree=600, nodesize=6)
rffsPredictions2 = predict(rffs2Model,test4Imputed)
ToFile(rffsPredictions2,"randomForest600FeatureSelectionOneRCompleteImputed.csv")
```

0.81901

```{r}
trainImputedComplete = cbind(trainImputed,carreteraNumero,carreteraLetras)
trainImputedComplete = trainImputedComplete[,-15]
rffs2Model = randomForest(f1, trainImputed[,c(-5)],ntree=600, nodesize=6)
rffsPredictions2 = predict(rffs2Model,test4Imputed)
ToFile(rffsPredictions2,"randomForest600FeatureSelectionOneRExtendedImputed.csv")
```

0.81901

```{r}
carreteraCHR = as.character(test4Imputed$CARRETERA)
carreteraCHR2 = lapply(carreteraCHR,function (x) strsplit(x,"-"))
carreteraLetras = as.character(lapply(carreteraCHR2,function(x) return(x[[1]][1])))
carreteraNumero = as.character(lapply(carreteraCHR2,function(x) return(x[[1]][2])))
for( i in 1:(dim(test4Imputed)[1])){
  if(test4Imputed[i,14] == "OTRO TIPO"){
    #print(i)
    if(carreteraLetras[i] == "AP"){ #Autopista con peaje, la englobamos en autopista
      test4Imputed[i,14] = "AUTOPISTA"

    }
    else if(carreteraLetras[i] == "A"){ #Autopistas libres y autovías
      test4Imputed[i,14] = "AUTOVIA"
      
    }
    else if(carreteraLetras[i] == "N"){ #Carreteras nacionales y de doble calzada
      test4Imputed[i,14] = "VIA CONVENCIONAL"
      
    }
    else if(length(carreteraLetras[i]) == 2 && length(carreteraNumero) == 2 ){ #Puede ser cualquier tipo de carretera, depende del número de cifras.
      test4Imputed[i,14] = "AUTOVIA"
      
    }
    else if(length(carreteraLetras[i]) == 2 && length(carreteraNumero) == 4 ){ #Puede ser cualquier tipo de carretera, depende del número de cifras.
      test4Imputed[i,14] = "CAMINO VECINAL"
    }
    else{
      test4Imputed[i,14] = "VIA CONVENCIONAL"
    }
  }
}
```

```{r}

rffs2Model = randomForest(f1, trainImputed[,c(-5)],ntree=600, nodesize=6)
rffsPredictions2 = predict(rffs2Model,test4Imputed)
ToFile(rffsPredictions2,"randomForest600FeatureSelectionOneRExtendedImputedTrainAndTest.csv")
```


#Gráfica de la evolución de la puntuación con los modelos
