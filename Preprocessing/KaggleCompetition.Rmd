---
title: "PreprocesamientoKaggle"
author: "Laura del Pino Díaz"
date: "13/2/2017"
header-includes: \usepackage[spanish]{babel}
output: pdf_document
toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width=60)
knitr::opts_chunk$set(comment = "", warning = FALSE, message = FALSE, echo = TRUE, tidy = TRUE, size="small")
```
\newpage

#Preprocesamiento y clasificación

##Objetivo del proyecto

El objetivo de este proyecto es clasificar lo más correctamente posible los accidentes de tráfico recogidos en la base de datos. Para ello tendremos que aplicar los conocimientos obtenidos sobre preprocesamiento y las distintas técnicas de clasificación aprendidas, de forma que no nos quedemos con un modelo único de clasificación, sino que vayamos iterando sobre uno inicial y mejorándolo en cada iteración. 

##La base de datos
La base de datos está divida en datos de entrenamiento y datos de test. Los datos de entrenamiento recogen 30002 instancias de 30 variables con la variable clase asignada, mientras que la partición de test contiene 19998 instancias y carece de la variable con la etiqueta asignada. 

```{r}
train  = read.csv("accidentes-kaggle.csv")
test = read.csv("accidentes-kaggle-test.csv")
```

##El formato de salida
El formato de salida será un fichero .csv en el que se muestra el identificador de la instancia y su valor de salida.

Como prueba de como funciona el envío a la plataforma Kaggle vamos a crear un fichero .csv que tiene el número de registros requeridos y una etiqueta 

```{r}
id = 1:19998
Prediction = rep(factor("Atropello"), 19998)
outputDataset = data.frame(id,Prediction)
write.table(outputDataset, file = "./Output.csv", sep = ",",row.names = FALSE)
```

Para facilitar la salida de los sucesivos ficheros de salida vamos a crear la siguiente función _ToFile_ al que se le pasa las predicciones para que las imprima.

```{r}
ToFile = function(Prediction,fileTitle = "Output.csv"){
Id = 1:19998
outputDataset = data.frame(Id,Prediction)
write.table(outputDataset, file = fileTitle, sep = ",",row.names = FALSE)
}
```

##Análisis de datos
Antes de desarrollar ningún tipo de modelo de clasificación debemos saber como está estructurada nuestra base de datos. Para ello miramos los tipos de datos:

```{r}
str(train)
```

La gran mayoría de las variables son categóricas representadas con factores de distintos niveles. El que llama la atención es la variable _HORA_ que tiene valores numéricos que se han interpretado como factores. Eso lo corregimos con la siguiente función. 

```{r}
train$HORA = as.numeric(as.character(train$HORA))
test$HORA = as.numeric(as.character(test$HORA))
```

###Análisis de valores perdidos
En la función _str_ también podemos ver que algunas variables presentan valores perdidos. Por lo que resultaría interesante saber el procentaje de estos valores perdidos.

```{r}
apply(train, 2, function(col)sum(is.na(col))/length(col))
```

Ante el alto porcentaje de valores perdidos de la variable ACOND_CALZADA, podríamos pensar que esta variable no contribuye a la clasificación, pero podríamos perder una variable que clasifique bien algún tipo de clase. Para probar esta hipótesis vamos a coger todos aquellos valores que no están perdidos y mirar la diversidad de clases que tiene asociadas. 

```{r}
levels(as.factor(train[which(is.na(train$ACOND_CALZADA)), "TIPO_ACCIDENTE"]))
```
 Como vemos salen todos los niveles posibles, por lo que no favorece la clasificación de ninguna clase, con lo que gana votos para ser eliminado ante una selección de características. 
 
###Estudio de los estadísticos principales.

Una aproximación al comportamiento de las variables con las que estamos trabajando son los valores de los estadísticos principales, es decir, de la media, mediana,cuartiles en conjunto con el valor máximo y mínimo. En el caso de las variables no numéricas, es decir, todas aquellas que son categóricas lo que obtendremos es una relación de los valores más frecuentes con dicha frecuencia. 


```{r}
summary(train)
```

En el caso de la variable _TOTVICTIMAS_ vemos que la gran mayoría de los registros tienen el valor 1 hasta el tercer cuartil, puede ser una variable decisiva en algún arbol de desición, para distinguir entre algunas clases o por el contrario no aportar información en la gran mayoría de los casos. 
Como esta variable, las variables _TOTMUERTOS_, _TOTHERIDOSGRAVES_ no varían su valor hasta pasado el tercer cuartil. 
Las restantes variables numéricas tienen un comportamiento similar, pero su valor si se modifica antes del tercer cuartil. 
Si nos fijamos el el valor máximo, de las variables numérticas, tenemos que difieren significativamente, tanto que ante un test de distancia intercuartil para la determinación de anomalías, todos ellos saldrían como anomalías. No vamos a eliminar los registros con dichos valores porque se puede dar el caso de que sean anomalías en esta variable pero en combinación con otras variables sea un valor _"normal"_ .

Veámoslo en un boxplot:

```{r}
library(graphics)
boxplot(train[,8:12],use.cols=TRUE,las = 2)
```

###Estudio de la correlación

De estas variables continuas podemos estudiar la correlación entre ellas. 

```{r}
cor(train[,8:12])
```

Se puede observar que el número de víctimas y el número de heridos leves está muy correlado, de hecho el 87% de los casos de uno se explician con el otro. Si este porcentaje  fuese mayor me plantearía eliminar una de las dos, por ahora eliminarlo solo quedaría si necesitase entrenar un modelo y por el volumen de datos su aprendizaje fuese lento. 

###Relaciones de las variables con la salida

Todos los pasos anteriores se han concentrado en las variables numéricas, obviando la existencia de las variables categóricas. En este punto del análisis de datos vamos a estudiar cómo se relacionan con la salida. 

```{r}

plot(train[,c(-1,-3-8,-9,-10,-11,-12)])
```

#Aproximación 1: árbol de desición. 

 Como primera aproximación vamos a utilizar un modelo de árbol de desición. Uno de los modelos más robustos ante anomalías.  Para este caso vamos a determinar que ignore todos aquellos valores perdidos. 
 
```{r}
library(tree)
train2 = train[,c(-5,-15)] #Se eliminan aquellas variables que generan problemas con el algoritmo tree.
test2 = test[,c(-5,-15)]
test2$HORA = as.numeric(test2$HORA)
treeModel = tree(TIPO_ACCIDENTE~., train2)
treePredictions = predict(treeModel,test2,type = "class")
treePredictions

ToFile(treePredictions,"TreeTest.csv")
```

El resultado obtenido por este modelo ha sido 0.81832

#Aproximación 1b: árbol de decisión con selección de características.

Del análisis previo tenemos la variable ACOND_CALZADA como variable que no aporta mucha informaición ya que en el 78% de sus valores están perdidos y el resto de las instancias  pueden corresponde con alguna de las seis clases, por lo que no ayuda en la clasificación. En esta aproximación quiero desarrollar un modelo del tipo árbol, eliminando esta variable y comprobar si da un resultado igual al anterior. 

```{r}
test3 = test2[,-18]
train3 = train2[,-18]
treeModel = tree(TIPO_ACCIDENTE~., train3)
treePredictions = predict(treeModel,test3,type = "class")
treePredictions

ToFile(treePredictions,"TreeTest2.csv")
```

Este modelo ha obtenido una ligera mejora con respecto con el anterior: 0.00059 teniendo una puntuación final de 0.81891.

#Aproximación 1b2: árbol de decisión con selección de características y imputación de valores. 

En los anteriores modelos hemos ignorardo los valores perdidos en la construcción del modelo. En esta variante vamos a realizar una imputación de valores. 
```{r}
library(mice)

#imputedData = mice(train, m=5, method = "pmm") Comentado para que no se ejecute en llamadas sucesivas de Rmarkdown dado que tarda un día en terminar su ejecución
#trainImputed = complete(imputedData)
#write.csv(trainImputed,"./imputedData.csv") <-data set con los valores imputados en la primera ejecución de mice.
```
Comprobemos que los porcentajes de valores perdidos se han reducido tras la imputación
```{r}
originalNAs = apply(train, 2, function(col)sum(is.na(col))/length(col)) 
imputedNAs = apply(trainImputed, 2, function(col)sum(is.na(col))/length(col))
data.frame(originalNAs,imputedNAs)
```

Podemos ver que no tenemos ningún valor perdido. Ahora entrenamos otra estructura de tipo árbol con esta nueva base de datos. 

```{r}
treeModel = tree(TIPO_ACCIDENTE~.-ACOND_CALZADA, (trainImputed[,c(-5,-15,-18)]))
treePredictions = predict(treeModel,test2,type = "class")
ToFile(treePredictions,"TreeTest2.csv")
```

Este modelo en la clasificación a obtenido una puntuación de 0.81891 lo que no es una mejora con respecto al método anterior. Esto también se puede leer como la ausencia de valores y la imputación de los mismos hace el mismo efecto, por lo que a partir de ahora vamos a proseguir con árboles de desición con el dataset completo para evitar problemas de característ. 

#Aproximación 1c: Random forest

TODO: hacer una intro de random forest

```{r}
library(randomForest)
library(mice)

subsetTrainImputed = trainImputed[,c(-7,-15,-29)]
RFModel = randomForest( TIPO_ACCIDENTE~.,data = subsetTrainImputed)
test4 = test[,c(-7,-15,-29)]
RFPredictions = predict(RFModel,test4)
ToFile(RFPredictions,"RandomForest.csv")
```

Si visualizamos el archivo, nos encontramos con que la infinita mayoría de los valores se han determinado como valores perdidos, por lo que no testeamos este modelo en la plataforma Kaggle. 

#Aproximación 1c2: Randomforest con valores imputados en el conjunto de test

```{r}
test4Imputed = complete(mice(test4, method = "pmm",m=1))
RFModel = randomForest( TIPO_ACCIDENTE~.,data = subsetTrainImputed)
iRFPredictions = predict(RFModel,test4Imputed)
ToFile(iRFPredictions,"iRandomForest.csv")
```

0.82938 	

#Aproximación 1c3: RandomForest con un mayor número de árboles y con valores imputados en el conjunto de test

##600 árboles

```{r}

RFModel2 = randomForest( TIPO_ACCIDENTE~.,data = subsetTrainImputed, ntree=600)
iRFPredictions = predict(RFModel2,test4Imputed)
ToFile(iRFPredictions,"it600RandomForest.csv")
```

0.82988

##1000 árboles

```{r}

RFModel2 = randomForest( TIPO_ACCIDENTE~.,data = subsetTrainImputed, ntree=1000)
iRFPredictions = predict(RFModel2,test4Imputed)
ToFile(iRFPredictions,"it1000RandomForest.csv")
```

0.82918 añadir más árboles no implica una mejoría. 

